<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1.0">
<link rel="stylesheet" href="../../../seminar.css">
<style>
body.seminar{
background: #828282;
}
</style>
<title>2. Q学習</title>
</head>
<body class="seminar">

<div class="container">

<div class="btback"><a href="../#text05">メニューへ戻る</a></div>
<div class="btback"><a href="./page01.html">前のページ</a></div>
<div class="btback"><a href="./page03.html">次のページ</a></div>

<div class="contents">

<h1>2. Q学習の概要</h1>

<p>
「Q学習」は強化学習のひとつで、ある「環境」の中を自分の代わりに「エージェント(代理人)」が動き回るというコンピュータシミュレーションを何度も繰り返すことで最善の行動を学習するという仕組みとなっています。具体的には、エージェントがある状況で何らかの行動をした時に、環境からもらえる報酬を最大にする様な行動をトライ＆エラーを繰り返しながら学習します。
</p>

<p>
この説明では分かりにくいので、例えば前のページで例として挙げた「遊園地にある迷路を脱出する問題」を考えてみましょう。自分が迷路の中に入って迷いながら出口を見つけるのはとても疲れて大変です。もちろん遊園地から地図をもらえば問題は解決するのですが、それでは全く面白くありませんね。そこで自分の代わりにロボットに出口を見つけてもらうことにします。
</p>

<p>
さてロボットが入り口から入って迷路をしばらく進むと右と左に道が分岐していました。最初の分岐点に関する情報は何も無いのでロボットは適当に左を選択しますが行き止まりにぶつかってしまいます。そこでロボットは「最初の分岐点で左に進むと行き止まり」ということを学習し、入り口に戻って最初からやり直します。最初の分岐点で右に進んでしばらく進むとまた右と左に道が分岐していました。でも2番目の分岐点に関する情報は無いのでやはり適当に方向を選択することにしました・・・
</p>

<p>
という様なトライ＆エラーを繰り返しながらロボットは出口までの道のりを調べていく訳ですが、今回の例では
</p>

<p>
「環境」 ＝ 迷路
</p>

<p>
「エージェント」 ＝ ロボット
</p>

<p>
「状況」 ＝ 分岐点
</p>

<p>
「行動」 ＝ 方向を選ぶ
</p>

<p>
「報酬」 = 方向を選んだ時にもらえる得点(マイナスならペナルティ)
</p>

<p>
となります。なお報酬の決め方には特にルールは無いのですが、例えば
</p>

<p>
ルール1： 行き止まりにぶつかったら -100 点
</p>

<p>
ルール2： 行き止まりでなかったら 10 点
</p>

<p>
ルール3： 出口にたどり着いたら 100 点
</p>

<p>
などとすると良いかもしれません。するとロボットは分岐点で報酬がたくさんもらえる方向を選択するように学習していきます。
</p>


</div>

<div class="btback"><a href="../#text05">メニューへ戻る</a></div>
<div class="btback"><a href="./page01.html">前のページ</a></div>
<div class="btback"><a href="./page03.html">次のページ</a></div>

</div>


</body>
</html>
