<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1.0">
<link rel="stylesheet" href="../../../common.css">
<script src="../../../common.js"></script>
<script src="../../../mathjax.js"></script>
<title>1.自己回帰モデル</title>
</head>
<body>

<nav class="brcr">
<ol>
<li><a href="../">アクティビティ: 自己回帰モデル</a></li>
<li>学習項目: [1] 自己回帰モデル</li>
<li><script>GetTitle()</script></li>
</ol>
</nav>

<h2><script>GetTitle()</script></h2>

<p>
あるディジタル信号列 $x[i]$ が次の式に従って確率的に生成されているとき、この $x[i]$ は<b> L 次 <a href="https://ja.wikipedia.org/wiki/%E8%87%AA%E5%B7%B1%E5%9B%9E%E5%B8%B0%E3%83%A2%E3%83%87%E3%83%AB">自己回帰モデル</a></b>( Auto-Regressive model : AR モデル )に従って生成されていると言います。
<br>
この L 次自己回帰モデルは記号 AR(L) で表されます。
</p>

<div class="info">
<input type="checkbox"><b>定義： L 次自己回帰モデル AR(L): </b>

<p>
次数 $\textrm{L}$ を正の整数とした時
</p>

\begin{align*}
x[i]
& = -\sum_{n=1}^{\textrm{L}} \{ a[n] \cdot x[i-n] \} \} + e[i] \\
& = -a[1] \cdot x[i-1] -a[2] \cdot x[i-2] - \cdots -a[\textrm{L}] \cdot x[i-\textrm{L}] + e[i] \\
\end{align*}

<p>
$a[n]$ ・・・ LPC 係数 (Linear Prediction Coefficient: 線形予測係数 )
</p>

<p>
$e[i]$ ・・・正規乱数などの任意のホワイトノイズ (平均 0、分散 $\sigma^2$)
</p>

<p>
※ 文献によっては LPC 係数の前にマイナスが付かない定義もあります
</p>

</div>

<p>
$x[i]$ は確率変数になるので、信号列を生成する毎に異なる信号列が出てくることに注意して下さい。
<br>
また次数 L と LPC 係数 $a[n]$ の値は本来は未知数なのですが、とりあえず今の所は既知であるとします。
<br>
なお  LPC 係数の前にマイナスが付いている理由は歴史的な背景によるもの(？)なので特に気にしなくても結構です。
</p>

<p>
さてこの L 次自己回帰モデルは次のブロック図で表されます。
</p>

<div class="info">
<input type="checkbox"><b> L 次自己回帰モデルのブロック図: </b>

<p>　</p>

<img src="./img/page01-fig1.png" alt="">
</div>

<p>
要するにホワイトノイズ $e[i]$ を入力すると確率変数 $x[i]$ が出力される<a href="../../d-filter/text03/page01.html">標準形 L 次 IIR フィルタ</a>となります。
<br>
ただし後段フィードフォワード部の IIRフィルタ係数は b[0] = 1 で残りは b[n] = 0 なので、プログラム表現は以下の通りに簡略化されます。
</p>

<div class="info">
<input type="checkbox"><b> L 次自己回帰モデルのプログラム表現: </b>

<pre class="wrap">
x[i] = 任意のホワイトノイズ 
for( int n = 1; n &lt= L; ++n ) x[i] += -a[n] * x[i-n]; // a[n]の符号注意
</pre>

</div>

<p>
なお L 次自己回帰モデルを IIR フィルタとみなした際の伝達関数
</p>


\[
\textrm{H}(z) 
 = \frac{1}{ 1 + a[1] \cdot z^{-1} + a[2] \cdot z^{-2} + \cdots + a[\textrm{L}] \cdot z^{-\textrm{L}} }
\]

<p>
の分母が 0 になる条件式、つまり
</p>

\[
z^{\textrm{L}} + a[1] \cdot z^{\textrm{L}-1} + a[2] \cdot z^{\textrm{L}-2} + \cdots + a[\textrm{L}] = 0
\]

<p>
を<b>特性多項式</b>と呼び、$x[i]$が<a href="../../acr/text01/page01.html">定常</a>であるためにはこの IIR フィルタが安定であること、つまり<a href="../../d-filter/text01/page11.html">特性多項式の全ての根が単位円の内側にある必要</a>があります。
</p>

<p>
※ 定常でない状態を<a href="https://ja.wikipedia.org/wiki/%E3%83%A9%E3%83%B3%E3%83%80%E3%83%A0%E3%82%A6%E3%82%A9%E3%83%BC%E3%82%AF">ランダムウォーク</a>といいます
</p>


<p>
そしてもし $x[i]$ が定常ならば、平均は
</p>

\[
\textrm{E}(x[i]) = 0
\]

<p>
となります。
</p>
<p>
一方、分散と共分散の計算は少しややこしくなります。
</p>
<p>
まず整数 $n$ を遅延時刻(ラグ)とおいた時に分散・共分散を $\gamma[n] = Cov \left ( x[i], x[i-n] \right )$、自己相関係数 を$\rho[n]$ とします。
<br>
すると $x[i]$が定常過程であることから
</p>

\[
Cov \left ( x[i-n], x[i-n] \right ) = Cov \left ( x[i], x[i] \right ) = \gamma[0]
\]

<p>
なので
</p>

\begin{align*}
\rho[n] &= \frac{ Cov \left ( x[i], x[i-n] \right ) }{ \sqrt{ Cov \left ( x[i], x[i] \right ) } \sqrt{ Cov \left ( x[i-n], x[i-n] \right ) } } \\
&= \frac{\gamma[n]}{\gamma[0]}
\end{align*}

<p>
という関係が出てきます。
</p>

<p>
また自己相関係数 $\rho[n]$ の値は以下の Yule-Walker 方程式と呼ばれる方程式を解くことで求めることが出来ます($\rho[0]$ は 1 )。
</p>

<div class="info">
<input type="checkbox"><b> 自己相関係数 $\rho[n]$ を求める Yule-Walker 方程式: </b>

<p>
※ $\rho[0] = 1$ 
</p>

\[
\begin{array}{rrrrrc}
\rho[0]\cdot a[1] & +\rho[1]\cdot a[2] & +\rho[2]\cdot a[3] & +\cdots & +\rho[\textrm{L}-1]\cdot a[\textrm{L}] & =-\rho[1] \\
\rho[1]\cdot a[1] & +\rho[0]\cdot a[2] & +\rho[1]\cdot a[3] & +\cdots & +\rho[\textrm{L}-2]\cdot a[\textrm{L}] & =-\rho[2] \\
\rho[2]\cdot a[1] & +\rho[1]\cdot a[2] & +\rho[0]\cdot a[3] & +\cdots & +\rho[\textrm{L}-3]\cdot a[\textrm{L}] & =-\rho[3] \\
 &  & \vdots &  &  &  \\
\rho[\textrm{L}-1]\cdot a[1] & +\rho[\textrm{L}-2]\cdot a[2] & +\rho[\textrm{L}-3]\cdot a[3] & +\cdots & +\rho[0]\cdot a[\textrm{L}] & =-\rho[\textrm{L}] \\
\end{array}
\]

</div>

<p>
では準備が終わったので、まずは分散 $\gamma[0]$ を求めてみましょう。
</p>

<p>
$\sigma^2$ をホワイトノイズの分散としたとき、$\gamma[0]$ は以下のように変形できます。
</p>

\begin{align*}
\gamma[0] &= Cov \left ( x[i], x[i] \right ) \\
&= Cov \left ( -a[1] \cdot x[i-1] -a[2] \cdot x[i-2] - \cdots -a[\textrm{L}] \cdot x[i-\textrm{L}] + e[i] , x[i] \right ) \\
&= -a[1] \cdot \gamma[1] - a[2] \cdot \gamma[2] - \cdots - a[\textrm{L}] \cdot \gamma[\textrm{L}] + \sigma^2 \\
&= -a[1] \cdot \rho[1] \cdot \gamma[0] - a[2] \cdot \rho[2] \cdot \gamma[0] - \cdots - a[\textrm{L}] \cdot \rho[\textrm{L}] \cdot \gamma[0] + \sigma^2
\end{align*}

<p>
よって
</p>

\[
\gamma[0] = Cov \left ( x[i], x[i] \right ) = \frac{\sigma^2}{1 +a[1] \cdot \rho[1] + a[2] \cdot \rho[2] + \cdots + a[\textrm{L}] \cdot \rho[\textrm{L}] }
\]

<p>
と分散が得られます。
</p>

<p>
ここまで来たら共分散 $\gamma[n]$ は漸化式
</p>

\begin{align*}
\gamma[n] &= Cov \left ( x[i], x[i-n] \right ) \\
&= Cov \left ( -a[1] \cdot x[i-1] -a[2] \cdot x[i-2] - \cdots -a[\textrm{L}] \cdot x[i-\textrm{L}] + e[i] , x[i-n] \right ) \\
&= -a[1] \cdot \gamma[n-1] - a[2] \cdot \gamma[n-2] - \cdots - a[\textrm{L}] \cdot \gamma[n-\textrm{L}]
\end{align*}

<p>
を使って順次求められます。
</p>

<br>
<script>PreNext(1,5)</script>
</body>
</html>
