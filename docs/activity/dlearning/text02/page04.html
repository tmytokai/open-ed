<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1.0">
<link rel="stylesheet" href="../../../common.css">
<script src="../../../common.js"></script>
<script src="../../../mathjax.js"></script>
<title>4. ディープラーニングの実行</title>
</head>
<body>

<nav class="brcr">
<ol>
<li><a href="../">アクティビティ: TensorFlow によるディープラーニング</a></li>
<li>学習項目: [2] ディープラーニングの基本</li>
<li><script>GetTitle()</script></li>
</ol>
</nav>

<h2><script>GetTitle()</script></h2>

<h3>
1. ディープラーニングの概要
</h3>

<p>
前ページで(3 層)ニューラルネットワークのデータフローグラフの作り方を学びました。ただし隠れ層と出力層の重み変数やバイアス変数はまだ乱数で初期化したままですので、今のままでは全く意味の無い出力がネットワークから出てきます。そこでここではニューラルネットワークの機械学習(※)、すなわち「ディープラーニング」について簡単に説明したいと思います。
</p>

<p>
※ 動物の学習プロセスをソフトやハードで再現する技術一般のことを「機械学習」とか「マシンラーニング」と呼びます。
</p>

<p>
ディープラーニングを一言で説明すれば「教師データを与えた時に理想的な出力がされるようにニューラルネットワークの重み変数やバイアス変数の値を決めること」となります。教師データとは文字通りニューラルネットワークを教育するための教師役のデータのことです(※)。
</p>

<p>
※ 教師データが無い場合の機械学習もありますが今回は取り扱いません。
</p>

<p>
この教師データは更に入力側の教師データと出力側の教師データに分かれていて、入力側の教師データを学習中のニューラルネットワークに入れて出てきた出力と出力側の教師データがそっくりになるように重みとバイアスが更新されます。ただし人間と同様に一回で学習するのは無理なので何千回も何万回も何億回も学習を繰り返す必要があります(※)。
</p>

<p>
※ 英単語の暗記をイメージして下さい。英単語が入力側の教師データ、日本語訳が出力側の教師データ、ニューラルネットワークがみなさんの脳です。暗記するまで何回も学習を繰り返しますよね。
</p>

<p>
という訳で教師データをかき集めたら、入力側と出力側に教師データを分けてそれぞれをデータフローグラフ化する必要があります。ここで出力側の教師データは別名「ラベル」と呼ばれますので、特に断りの無い限り入力側の教師データを単に「教師データ」、出力側の教師データを「ラベル」と呼ぶことにします。また教師データとラベルの組は全部で L 組あるとします。
</p>

<br>
<h3>
2. 教師データのデータフローグラフ
</h3>

<p>
まずニューラルネットワークへの入力データとなる教師データをデータフローグラフ化してみます。
</p>

<p>
今回取り扱っている 3 層ニューラルネットワークの入力データは N 次元ベクトルとしたので教師データ 1 個も  N 次元ベクトルとなります。例えば$i$ 番目の教師データはベクトル $\{x_{i1}, x_{i2}, \cdots, x_{iN}\}$ で表すことができます。この様な教師データとしては画像データのピクセル値とか音声データの FFT 係数とか、データの種類によって色々な形式が考えられます。
</p>

<p>
さてその様なデータが全部で L 組あるので、教師データ全体は図 1 の様に L x N 行列の定数で表す事が出来ます(※)。
</p>

<p>
※ 前のページの入力データの様に 1 x N 行列でなく、わざわざ L x N 行列にしている理由は後で説明します。
</p>

<div class="info">
<input type="checkbox"><b>図1: 教師データのデータフローグラフ:</b>

<p>
L x N 行列の教師データを定数 OP ノード として表現する
<br>
$[x_{i1}, x_{i2}, \cdots, x_{iN}]$ が $i$ 番目の教師データとなる

</p>

<img src="./img/page04-fig1.png" alt="">
</div>

<br>
<h3>
3. ラベルのデータフローグラフ
</h3>

<p>
次は出力側の教師データ、つまりラベルをデータフローグラフ化してみます。
</p>

<p>
今回取り扱っている 3 層ニューラルネットワークの出力は M 次元ベクトルとしたのでラベル 1 個も  M 次元ベクトルとなります。例えば$i$ 番目のラベルはベクトル $\{y_{i1}, y_{i2}, \cdots, y_{iM}\}$ で表すことができます。
</p>

<p>
さてラベルの形式も入力側と同様に色々と考えられるのですが今回は「分類問題」を取り扱いたいと思います。分類問題におけるラベルは文字通り入力された教師データを分類するためのラベルとなり、M は分類クラス数となります。
</p>

<p>
例えば教師データが画像データで、各画像データを猫と犬と鳥の 3 クラス(M = 3)の画像に分類したい場合を考えてみましょう。この場合、$i$ 番目の教師データが猫画像だったら $y_{i1} = 1$ で他は 0、犬画像だったら $y_{i2} = 1$ で他は 0、鳥画像だったら $y_{i3} = 1$ で他は 0 という風に考えて次のようなラベルを各画像に割り振ります。
</p>

<p>
猫ラベル・・・ $\{1,0,0\}$
<br>
犬ラベル・・・ $\{0,1,0\}$
<br>
鳥ラベル・・・ $\{0,0,1\}$
</p>

<p>
その様なラベルが全部で L 組ある訳ですので、ラベル全体は図 2 の様に L x M 行列の定数で表す事が出来ます。
</p>

<div class="info">
<input type="checkbox"><b>図2: ラベルのデータフローグラフ:</b>

<p>
L x M 行列のラベルを定数 OP ノード として表現する
<br>
$[y_{i1}, y_{i2}, \cdots, y_{iM}]$ が $i$ 番目のラベルとなる

</p>

<img src="./img/page04-fig2.png" alt="">
</div>

<br>
<h3>
4. クロスエントロピー
</h3>

<p>
教師データとラベルの準備が出来たので、次は教師データをニューラルネットワークに入れて出てきた出力とラベルの値が「そっくり」になるように重みとバイアスをディープラーニングにより更新したいと思います。
</p>

<p>
ところが何らかの指標が無いと出力とラベルがそっくりかどうか分かりませんのでディープラーニングを行うことは出来ません。そこでまず「出力とラベルのそっくり度」を測るための指標を何かひとつ決めなければいけません。この指標は色々ありますが今回は「クロスエントロピー」を利用したいと思います。
</p>

<p>
まず $i$ 番目の教師データ  $\{x_{i1}, x_{i2}, \cdots, x_{iN}\}$ をニューラルネットワークに入れて出てきた出力をベクトル $\{y'_{i1}, y'_{i2}, \cdots, y'_{iM}\}$ とします。ここで今回は出力層のパーセプトロンの活性化関数を SoftMax 関数としたので、
</p>

<p>
\[
0 \leq y'_{ij}\leq 1 \ ,\  \sum_{j=1}^M y'_{ij} = 1
\]
</p>

<p>
という関係が成り立ちます。つまり、
</p>

<p>
<b>
「$y'_{ij}$ は $i$ 番目の教師データがクラス $j$ に属する確率」
</b>
</p>

<p>
を表します(※)。
</p>

<p>
※ ここ大事なポイントですので良く覚えておいて下さい。ちなみにラベルはある教師データがあるクラスに属する確率が 1 という事を意味しています。
</p>

<p>
さて $i$ 番目の教師データに割り振ったラベル $\{y_{i1}, y_{i2}, \cdots, y_{iM}\}$ を使うと、クロスエントロピーは次のように定義されます。
</p>

<p>
\[
H(y,y') = -\sum_{i=1}^L \sum_{j=1}^M y_{ij}\log y'_{ij}
\]
</p>

<p>
このクロスエントロピー $H(y,y')$ は
</p>

<p>
<b>
<ol>
<li>出力とラベルが似てない程 $H(y,y')$ の値は大きくなる</li>
<li>出力とラベルが似てる程 $H(y,y')$ の値は小さくなる</li>
</ol>
</b>
</p>

<p>
というとても良い性質を持っていますので「出力とラベルのそっくり度」を測る指標として用いることが出来ます。言い換えれば $H(y,y')$ が可能な限り小さくなる様に重みとバイアスの値を更新すれば良い事が分かります。
</p>

<br>
<h3>
5. クロスエントロピーのデータフローグラフ
</h3>

<p>
執筆中
</p>

<br>
<h3>
6. ディープラーニングの実行
</h3>

<p>
執筆中
</p>


<script>PreNext(4,5)</script>
</body>
</html>
