<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1.0">
<link rel="stylesheet" href="../../../common.css">
<script src="../../../common.js"></script>
<script src="../../../mathjax.js"></script>
<title>4. TensorFlowによるMLPの学習</title>
</head>
<body>

<nav class="brcr">
<ol>
<li><a href="../">アクティビティ: TensorFlow/Keras によるディープラーニング</a></li>
<li>学習項目: [2] TensorFlow を用いた MLP の学習</li>
<li><script>GetTitle()</script></li>
</ol>
</nav>

<h2><script>GetTitle()</script></h2>

<br>
<h3>
1. 学習データセットによるディープラーニングの実行
</h3>

<p>
<a href="./page03.html">前ページ</a>で 3 層ニューラルネットワークを構築しました。
<br>
ただし隠れ層と出力層の重みやバイアス( w_h、b_h、w_o、b_o の4つの変数) を乱数で初期化していましたので、入力信号 data を入力しても全く意味の無い出力信号 y_o が出力されます。
<br>
したがって、何らかの入力信号を与えた時に理想的な出力がされるように「<a href="https://ja.wikipedia.org/wiki/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0">ディープラーニング</a>」を使ってニューラルネットワークを学習させる必要があります。
</p>

<p>
なお「<b>多クラス分類</b>」を扱う場合は理想的な出力信号のことを「<b>ラベル</b>」と呼んでいます。
<br>
今回のアクティビティでは「多クラス分類問題」を取り扱いますので、これ以降は理想的な出力信号のことをラベルと呼びます。
</p>

<p>
さて適切に学習を行うためには学習用入力信号とラベルの組を複数用意する必要があります。
<br>
学習用入力信号とラベルの組の全体集合を「<b>学習データセット</b>」と呼びます。
</p>
<p>
※ 文献によっては「訓練データセット」とか「教師データセット」と呼ぶこともあります
</p>

<p>
今回は学習データセットのサイズを L 、つまりデータセット内に入力信号とラベルの組が No.0 から No.(L-1) まで L 組あることにします。
</p>

<br>
<h3>
2. 学習用入力信号
</h3>

<p>
まず学習用入力信号について考えます。
</p>

<p>
学習用入力信号全体の名前を data_training とすると、学習データセットのサイズが L で、今考えている 3 層ニューラルネットワークの入力層のパーセプトロンの個数は N 個でしたので、 data_training は LxN 行列
</p>

\[
{\rm data\_training} = 
\begin{bmatrix}
t_{00} \ , & \cdots &,\  t_{\rm 0(N-1)} \\
\vdots & \ddots & \vdots \\
t_{\rm (L-1)0} ,  & \cdots &,\  t_{\rm (L-1)(N-1)} \\
\end{bmatrix}
\]

<p>
となります。ここで、
</p>
<p>
<b>
「data_training の j 行 i 列目の値 $t_{\rm ji}$ は学習データセット No.j に属し、入力層のパーセプトロン No.i に入力される入力信号の値」
</b>
</p>

<p>
を表します。
<br>
よって TensorFlow では学習用入力信号は図 1 の様に L x N 行列の<a href="../text01/page03.html#const">定数テンソル</a>で定義されます。
</p>

<div class="info">
<input type="checkbox"><b>図1: 学習用入力信号</b>

<p>
data_training : 学習用入力信号、 L x N 行列 (<a href="../text01/page03.html#const">定数テンソル</a>)
</p>
<p>
※ $t_{\rm ji}$ : 学習データセット No.j に属し、入力層のパーセプトロン No.i に入力される入力信号の値
</p>


<img src="./img/page04-fig1.png" alt="">
</div>

<br>
<h3>
3. 学習用ラベル
</h3>

<p>
次は学習用ラベルについて考えます。
</p>

<p>
今考えている 3 層ニューラルネットワークの出力層のパーセプトロンの個数は M 個で、学習データセットのサイズは L としましたので、 学習用ラベル全体の名前を label_training とすると、label_training は LxM 行列
</p>

\[
{\rm label\_training} = 
\begin{bmatrix}
l_{00}\ , & \cdots &,\  l_{\rm 0(M-1)} \\
\vdots & \ddots & \vdots \\
l_{\rm (L-1)0} \ , & \cdots &,\  l_{\rm (L-1)(M-1)} \\
\end{bmatrix}
\]

<p>
 で表すことができます。
<p>
となります。ここで、
</p>
<p>
<b>
「label_training の j 行 i 列目の値 $l_{\rm ji}$ は学習データセット No.j に属し、出力層のパーセプトロン No.i から出力される理想的な値(ラベル)」
</b>
</p>

<p>
を表します。
</p>

<p>
さて、このラベルの値をどのように決めるかについては色々な形式が考えられますが、今回は「<a href="https://ja.wikipedia.org/wiki/One-hot">one-hot ベクトル</a>形式」を使いたいと思います。
</p>

<p>
one-hot ベクトル形式とは、入力した信号があるクラスに属する場合は 1、それ以外は 0 とする様にラベルを決める形式です。
<br>
例えばニューラルネットワークに入力した画像信号を「猫」と「犬」と「鳥」の 3 クラスに分類したい場合を考えてみます。
</p>
<p>
この場合クラス数が 3 つなので M = 3 とし、猫をクラス No.0、犬をクラス No.1、鳥をクラス No.2 とします。
<br>
そして学習データセット No.j における入力画像が猫だったら $l_{j0} = 1$ 、犬だったら $l_{j1} = 1$ 、鳥だったら $l_{j2} = 1$ 、それ以外は 0 となりますので、各ラベルは
</p>

<p>
猫ラベル(クラス No.0)・・・ [1,0,0]
<br>
犬ラベル(クラス No.1)・・・ [0,1,0]
<br>
鳥ラベル(クラス No.2)・・・ [0,0,1]
</p>

<p>
と表されます。
</p>

<p>
この様にラベルの形式として one-hot ベクトルを使うと、

<p>
<b>
「label_training の j 行 i 列目の値 $l_{\rm ji}$ は学習データセット No.j に属する学習用入力信号がクラス No.i に属してるか(=1)、属していないか(=0)」
</b>
</p>

<p>
を表すようになります。
<br>
よってラベル label_training は図 2 の様に L x M 行列の<a href="../text01/page03.html#const">定数テンソル</a>で定義されます。
</p>


<div class="info">
<input type="checkbox"><b>図2: ラベル</b>

<p>
label_training : 学習用ラベル、 L x M 行列 (<a href="../text01/page03.html#const">定数テンソル</a>)
</p>

<p>
※ $l_{\rm ji}$ : 学習データセット No.j に属する学習用入力信号がクラス No.i に属してるか(=1)、属していないか(=0)
</p>

<img src="./img/page04-fig2.png" alt="">

</div>

<br>
<h3>
4. 予測値
</h3>

<p>
さて学習用入力信号 data_training は行列でしたので、data_training を 3 層ニューラルネットワークに入力して出てくる出力信号も行列になります。
<br>
この行列のことを「<b>予測値</b>」とか「<b>予測結果</b>」と呼びます。
</p>

<p>
ここで予測値の名前を predict とすると、predict は label_training と同様に LxM 行列
</p>

\[
{\rm predict} = 
\begin{bmatrix}
p_{00}\ , & \cdots &,\  p_{\rm 0(M-1)} \\
\vdots & \ddots & \vdots \\
p_{\rm (L-1)0}\ , & \cdots &,\  p_{\rm (L-1)(M-1)} \\
\end{bmatrix}
\]

<p>
になります。
</p>

<p>
ところで今回は出力層のパーセプトロンの活性化関数を<a href="../text01/page03.html#softmax">softmax 関数</a>としたため
</p>

<p>
\[
0 \leq p_{ji} \leq 1 \ ,\  \sum_{i=0}^{\rm M-1} p_{ji} = 1
\]
</p>

<p>
という関係が成り立っていますので、
</p>

<p>
<b>
「predict の j 行 i 列目の値 $p_{\rm ji}$ は学習データセット No.j に属する学習用入力信号がクラス No.i に属する確率の予測値」
</b>
</p>

<p>
を表します。
</p>

<br>
<h3 id="loss">
5. 損失関数
</h3>

<p>
学習データセットを用意したら、次は重みとバイアス( w_h、b_h、w_o、b_o の4つの変数)をディープラーニングにより学習します。
</p>

<p>
ただし何らかの指標が無いと正しく学習されているか分かりませんので、まずその指標を決める必要があります。
<br>
この指標の事を「<b>損失関数</b>(loss function)」、損失関数の戻り値を「<b>損失</b>(loss)」と呼びます。
</p>

<p>
この損失関数には色々な種類がありますが、今回は多クラス分類問題でよく使われている「<b>カテゴリカル・クロスエントロピー</b>(categorical cross entropy)」を利用したいと思います。
</p>

<p>
カテゴリカル・クロスエントロピーは上で定義した学習用ラベル(label_training)と予測値(predict)の要素 $l_{ji}$ と $p_{ji}$ を使って次の様に定義されます。
</p>

<div class="info">
<input type="checkbox"><b>定義: カテゴリカル・クロスエントロピーの定義</b>

<p>
\[
{\rm entropy} = -\sum_{j=0}^{\rm L-1} \sum_{i=0}^{M-1} l_{ji}\log p_{ji}
\]
</p>

</div>

<p>
上の式によって求められた値 entropy は
</p>

<ul>
<li><b>学習用ラベル(label_training)と予測値(predict)が似ていない → entropy は大</b></li>
<li><b>学習用ラベル(label_training)と予測値(predict)が似ている → entropy は小</b></li>
</ul>

<p>
という性質を持っていますので、entropy が可能な限り小さくなる様に重みとバイアスの値を学習・更新すれば良い事が分かります。
</p>

<p>
ところで上の定義式は<a href="../text01/page03.html#redsum">総和演算</a>を使って次のような行列演算で表すことができます。
</p>

<div class="info">
<input type="checkbox"><b>カテゴリカル・クロスエントロピーの行列演算</b>
<p>
entropy = - reduce_sum( log(predict)*label_training )
</p>

<p>
※ * は行列積ではなくてただの<a href="../text01/page03.html#mul">掛け算</a>
</p>

</div>

<p>
従ってカテゴリカル・クロスエントロピーの演算をデータフロー・グラフ化すると次のようになります。
</p>

<div class="info">
<input type="checkbox"><b>図3: カテゴリカル・クロスエントロピーのデータフロー・グラフ</b>

<p>
<br>
予測確率 predict に<a href="../text01/page03.html#log">log</a> を通し、ラベル label_training と<a href="../text01/page03.html#mul">掛け合わせる</a>、さらに<a href="../text01/page03.html#redsum">総和演算</a>をして -1 倍して entropy に出力する
</p>

<p>
※ 最後に -1 倍するのを良く忘れるので注意
</p>


<img src="./img/page04-fig3.png" alt="">
</div>


<br>
<h3 id="opt">
6. 最適化アルゴリズム
</h3>

<p>
さて損失が小さくなるように重みやバイアスを学習して更新するアルゴリズムを<b>最適化アルゴリズム</b>と呼びます。
</p>

<p>
最適化アルゴリズムには色々な種類があるのですが、今回は
</p>
<p>
・<a href="https://ja.wikipedia.org/wiki/%E7%A2%BA%E7%8E%87%E7%9A%84%E5%8B%BE%E9%85%8D%E9%99%8D%E4%B8%8B%E6%B3%95">SGD</a>(Stochastic Gradient Descent: 確率的勾配降下法)
</p>
<p>
・<b>Adam</b>(ADAptive Moment estimation)
</p>
<p>
の 2 つを取り扱います。
</p>
<p>
※ チュートリアルでは SGD が良く使われていますが、学習の収束速度が遅いので、実際には Adam が使われることが多いようです
</p>

<p>
この SGD や Adam を実行するためは非常に難しい数学の知識が必要なのですが、幸いなことに TensorFlow ではクラスとして既に用意されているので誰でも簡単に利用できます。
</p>

<div class="info">
<input type="checkbox"><b>SGD クラスと Adam クラス </b>

<p>
SGD クラス: tf.keras.optimizers.SGD( learning_rate=学習率 )
</p>

<p>
Adam クラス: tf.keras.optimizers.Adam( learning_rate=学習率 )
</p>

<p>
学習実行メソッド: minimize( lambda: 損失関数, [学習対象の変数のリスト] )・・・学習を1回実施する、戻り値は実施済み学習回数
</p>

</div>

<p>
ここで学習率(learning rate)は学習の精度と速度を表しています。
<br>
学習率の値が大きいほどニューラルネットワークは適当に学習しますが速く学習が進みます。
<br>
逆に値が小さいとニューラルネットワークはきちんと学習しますが遅く学習が進みます。
</p>

<p>
いずれにしろ 1 回では学習は終わりませんので、損失関数の値が十分小さくなるまで何回も学習を繰り返す必要があります。
</p>

<p>
例えば以下のソース 1 は Adam を用いた学習例です。
<br>
この例では学習対象である変数 x と y の初期値をそれぞれ 1,0 と-0.5、損失関数を ${\rm loss}() = x^2+y^2$、学習率を 0.1、学習回数を 50 回 としたとき、損失を最小にする x と y の値(x=0,y=0)を Adam を使って求めています。
</p>

<div class="info">
<input type="checkbox"><b>ソース 1: Adam による学習例</b>

<pre class="wrap">
import tensorflow as tf

# 学習対象の変数
x = tf.Variable([[1]], dtype=tf.float32)
y = tf.Variable([[-0.5]], dtype=tf.float32)

#損失関数
@tf.function
def loss():
    return x**2 + y**2

print(f'損失={loss().numpy()}');
print(f'x={x.numpy()}');
print(f'y={y.numpy()}');
print('')

opt = tf.keras.optimizers.Adam( learning_rate=0.1 ) # Adamクラスのインスタンス
#opt = tf.keras.optimizers.SGD( learning_rate=0.1 ) # SGD を使いたい場合はこちら
for i in range(50):  # 学習を50回繰り返す
    opt.minimize(lambda: loss(), [x,y])
    
print('結果')
print(f'損失={loss()}');
print(f'x={x.numpy()}');
print(f'y={y.numpy()}');
print('')
</pre>
</div>

<p>
結果は以下のようになります。
<br>
学習を50回繰り返すと損失が十分小さくなり、 (x,y) の値が loss() を最小する (0,0) に近づいていることが分かります。
</p>

<div class="info">
<input type="checkbox"><b>ソース 1 の結果</b>

<pre class="wrap">
損失=[[1.25]]
x=[[1.]]
y=[[-0.5]]

結果
損失=[[0.0007694]]
x=[[-0.00481954]]
y=[[-0.02731619]]
</pre>
</div>

<br>
<h3 id="batch">
7. ミニバッチ学習
</h3>

<p>
実際のディープラーニングでは学習データセットのサイズ L は膨大な数となるため、学習データセット全てを使って一気に学習を行うことは滅多にありません。
</p>

<p>
ではどうするかというと、学習データセットを更に「<b>バッチ(batch)</b>」と呼ばれるサブ学習データセットに細かく分割し、バッチ単位で学習を行います。
<br>
この学習方法のことを「<b>ミニバッチ学習</b>」といいます。
</p>

<p>
またバッチに含まれる入力信号とラベルの組の個数を「<b>バッチサイズ</b>」と呼び、慣習的には 32,64,128,256,・・・・ など 2 の n 乗の数が良く使われています。
</p>

<p>
なお、学習データセットのサイズとバッチサイズが同じ場合を「<b>バッチ学習</b>」、バッチサイズが 1 の場合を「<b>オンライン学習</b>」と言います。
</p>

<p>
ところで学習データセットのサイズが L でしたのでバッチは総数 L/B 個あります( L が B で割り切れない場合は今回は考えないことにします)。
<br>
バッチ No.0 から順にバッチ No.(L/B)-1 まで全てのバッチを使って一通り学習を済ませることを「<b>エポック</b>(epoch)」と呼び、エポックの繰り返し回数のことを「<b>エポック数</b>」と呼びます。
<br>
例えばエポック数が 3 で、学習データセットのサイズが L =6、バッチサイズが B=2 の時は次の様にして学習が繰り返されます。
</p>

<br>
<p>
学習開始
<br>
↓
<br>
(エポック 0 開始) パッチNo.0を使って学習 → パッチNo.1 を使って学習 → パッチNo.2 を使って学習 (エポック 0 終了) 
<br>
↓
<br>
(エポック 1 開始) パッチNo.0を使って学習 → パッチNo.1 を使って学習 → パッチNo.2 を使って学習 (エポック 1 終了) 
<br>
↓
<br>
(エポック 2 開始) パッチNo.0を使って学習 → パッチNo.1 を使って学習 → パッチNo.2 を使って学習 (エポック 2 終了) 
<br>
↓
<br>
エポックを 3 回繰り返したので学習終了
</p>

<br>
<p>
さてバッチの分割の仕方も色々考えられるのですが、今回は単純に学習データセットの先頭から順に取り出すことにします。
<br>
つまりバッチサイズを B としたとき、バッチ No.k の入力信号は BxN 行列
</p>

\[
{\rm data\_batch\_k} =
\begin{bmatrix}
t_{(B*k)0} \ , & \cdots &,\  t_{\rm (B*k)(N-1)} \\
\vdots & \ddots & \vdots \\
t_{\rm (B*k+B-1)0}\ ,  & \cdots &,\  t_{\rm (B*k+B-1)(N-1)} \\
\end{bmatrix}
\]


<p>
ラベルは BxM 行列
</p>

\[
{\rm label\_batch\_k} =
\begin{bmatrix}
l_{(B*k)0} \ , & \cdots &,\  l_{\rm (B*k)(M-1)} \\
\vdots & \ddots & \vdots \\
l_{\rm (B*k+B-1)0}\ ,  & \cdots &,\  l_{\rm (B*k+B-1)(M-1)} \\
\end{bmatrix}
\]

<p>
となります。
</p>

<p>
このバッチを使うと、カテゴリカル・クロスエントロピーは次のようなデータフロー・グラフで表されます。
<br>
なお予測値(predict)を求める 3 層ニューラルネットワークのデータフロー・グラフも図に含めています。
</p>

<div class="info">
<input type="checkbox"><b>図4: カテゴリカル・クロスエントロピー (ミニバッチ学習版)</b>

<p>
※ 今回は loss(data_batch_k,label_batch_k) という名前のオペレーションとして定義する
</p>

<img src="./img/page04-fig4.png" alt="">
</div>


<br>
<h3>
8. ディープラーニングの実行
</h3>

<p>
では全ての準備が整ったのでいよいよディープラーニングを実行してみましょう。
</p>

<p>
今回考えている 3 層ニューラルネットワークの場合、学習対象の変数は w_h、b_h、w_o、b_o の4つですので、結局のところ次のように書けばディープラーニングが実行されます。
</p>

<div class="info">
<input type="checkbox"><b>ソース 2: ディープラーニングの実行</b>

<pre class="wrap">
opt = tf.keras.optimizers.Adam( learning_rate=r ) # 最適化アルゴリズムは Adam
#opt = tf.keras.optimizers.SGD( learning_rate=r ) # SGD を使いたい場合はこちら
for e in range(E):
    for k in range(int(L/B)):
        print(f'\repoch {e} batch {k}', end='')
        data_batch_k = data_training[B*k:B*k+B]
        label_batch_k = label_training[B*k:B*k+B]
        opt.minimize(lambda: loss(data_batch_k,label_batch_k), [w_h,b_h,w_o,b_o])

※1 r : 学習率
※2 E : エポック数
※3 L : 学習データセットのサイズ
※4 B : バッチサイズ
※5 data_training, label_training : 学習用入力信号全体とラベル全体、
※6 w_h, b_h, w_o, b_o : 隠れ層の重み、隠れ層のバイアス、出力層の重み、出力層のバイアス
※7 loss(data_batch_k,label_batch_k) : カテゴリカル・クロスエントロピー(図4)
</pre>
</div>


<br>
<h3>
9. 検証データセットとテストデータセット
</h3>

<p>
いままでは学習データセットだけを考えていましたが、実際にディープラーニングを実行する場合は「<b>検証データセット</b>」と「<b>テストデータセット</b>」というデータセットも必要です。
</p>

<p>
検証データセットは学習データセットの様に検証用入力信号とそれに対応するラベルが組になっているデータセットです。
<br>
同様にテストデータセットもテスト用入力信号とそれに対応するラベルが組になっているデータセットです。
</p>

<p>
何が違うのか疑問に思うかもしれませんが
</p>

<ul>
<li><b>検証データセット ・・・学習中に、正しく学習されてるかチェックするため繰り返し使う(学習やテストには使わない)</b></li>
<li><b>テストデータセット・・・学習が終わってから、最終チェック用として最後に1回だけ使う(学習や検証には使わない)</b></li>
</ul>

<p>
という違いがあります。
</p>

<p>
学習データセットだけ使って評価してしまうと「<a href="https://ja.wikipedia.org/wiki/%E9%81%8E%E5%89%B0%E9%81%A9%E5%90%88">過学習</a>(オーバーフィッティング)」が生じてしまい、実際のデータに適合していないモデルが出来てしまうことがあります。
</p>

<p>
そこで検証データセットも学習中に併用し、過学習が起きてないか常に確認しながら慎重に学習を進める必要があります。
<br>
そしてもし過学習が生じてしまっている場合は、パラメータの数を見直したり、場合によってはモデルそのものを見直して最初から学習をやり直す必要があります。
</p>

<p>
さらに、学習データセットと検証データセットを使って無事に学習を終えたとしても、テストデータセットの損失が大きい場合は最終チェックに不合格ということですので、これまたパラメータの数やモデルを見直して最初から学習と検証をやり直す必要があります。
</p>

<br>
<h3 id="met">
10. 評価関数
</h3>

<p>
学習自体は上で説明した損失関数を使うのですが、損失関数が返す値は人間には分かりにくいという欠点があります。
<br>
そこで人間が評価しやすいように、損失関数とは別に「<b>評価関数</b>(metric function)」を損失関数と併用して学習結果を評価する場合があります。
</p>

<p>
損失関数と同じ様に評価関数にも色々な種類がありますが、今回は「<b>正解率</b>(accuracy)」を利用します。
<br>
今回の様に多クラス分類問題、かつラベルが one-hot ベクトル形式の場合は以下のソース 3 で示した関数によって計算できます。
</p>

<p>
※ 評価関数は学習には関係ないので TensorFlow を使わないでただの Python の関数として定義しています
</p>

<div class="info">
<input type="checkbox"><b>ソース 3: 正解率(カテゴリカルデータ用) </b>

<pre class="wrap">
def categorical_accuracy(predict,label):
    predict_amax = np.argmax(predict.numpy(),axis=1)
    label_amax = np.argmax(label.numpy(),axis=1)
    equal = np.equal(predict_amax, label_amax)
    return np.mean(equal)

※1 predict: 学習・検証・テストデータセットから求めた予測値
※2 label : 正しいラベル (one-hot ベクトル形式)
</pre>
</div>


<br>
<script>PreNext(4,5)</script>
</body>
</html>
