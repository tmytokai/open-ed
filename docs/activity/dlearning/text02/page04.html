<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1.0">
<link rel="stylesheet" href="../../../common.css">
<script src="../../../common.js"></script>
<script src="../../../mathjax.js"></script>
<title>4. ディープラーニングの実行</title>
</head>
<body>

<nav class="brcr">
<ol>
<li><a href="../">アクティビティ: TensorFlow によるディープラーニング</a></li>
<li>学習項目: [2] ディープラーニングの基本</li>
<li><script>GetTitle()</script></li>
</ol>
</nav>

<h2><script>GetTitle()</script></h2>

<br>
<h3>
1. ディープラーニングの概要
</h3>

<p>
<a href="./page03.html">前ページ</a>で 3 層ニューラルネットワークのデータフロー・グラフを作りましたが、隠れ層と出力層の重みやバイアス( w_h、b_h、w_o、b_o の4つ) は乱数で初期化していますので、このままでは入力信号 data を入力しても全く意味の無い出力信号 y_o が出力されます。
</p>
<p>
したがって、何らかの入力信号を与えた時に理想的な出力がされるように「<a href="https://ja.wikipedia.org/wiki/%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0">ディープラーニング</a>」を使ってニューラルネットワークを学習(＝重みやバイアスを適切な値を変化させる)必要があります。
</p>

<p>
改めて書くと、ディープラーニングの定義は
</p>
<p>
「<b>教師信号が与えられた時にそれに対応する理想的な信号が出力されるようにニューラルネットワークの重みやバイアスなどのパラメータ値を更新する<a href="https://ja.wikipedia.org/wiki/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92">機械学習(マシンラーニング)</a>の手法の一つ</b>」
</p>

<p>
です。
</p>

<p>
ここで「<b>教師信号</b>」とは文字通りニューラルネットワークを教育するための教師役となる信号のことで「<b>説明変数</b>」と呼ぶこともあります。
</p>
<p>
一方、ある教師信号を与えたときの理想的な出力信号のことを「<b>目的変数</b>」と呼びますが、特に「多クラス分類問題」を扱う場合は目的変数の事を「<b>ラベル</b>」と呼んでいます。
<br>
今回はこの「多クラス分類問題」を取り扱います。
</p>

<p>
※ 教師信号を用いる学習のことを「<a href="https://ja.wikipedia.org/wiki/%E6%95%99%E5%B8%AB%E3%81%82%E3%82%8A%E5%AD%A6%E7%BF%92">教師あり学習</a>」と呼びます。
<br>
逆に教師信号が無い機械学習の事を「<a href="https://ja.wikipedia.org/wiki/%E6%95%99%E5%B8%AB%E3%81%AA%E3%81%97%E5%AD%A6%E7%BF%92">教師なし学習</a>」と言いますが今回は取り扱いません。
</p>

<p>
なお学習を行うためには教師信号とラベルの組(「<b>訓練データセット</b>」と呼びます)を複数用意する必要があります。
<br>
今回は訓練データセットが No.0 から No.(L-1) まで L 組あることにします。
</p>

<br>
<h3>
2. 教師信号
</h3>

<p>
まず教師信号について考えます。
</p>

<p>
教師信号全体の名前を teacher とすると、訓練データセットのサイズが L で、今考えている 3 層ニューラルネットワークの入力層のパーセプトロンの個数は N 個でしたので、 teacher は LxN 行列
</p>

\[
{\rm teacher} = 
\begin{bmatrix}
t_{00} \ , & \cdots &,\  t_{\rm 0(N-1)} \\
\vdots & \ddots & \vdots \\
t_{\rm (L-1)0} ,  & \cdots &,\  t_{\rm (L-1)(N-1)} \\
\end{bmatrix}
\]

<p>
となります。
</p>

<p>
よって TensorFlow では教師信号は図 1 の様に L x N 行列の<a href="../text01/page04.html#const">定数テンソル</a>で定義され、
</p>

<p>
<b>
「teacher の j 行 i 列目の値 $t_{\rm ji}$ は訓練データセット No.j の教師信号において入力層のパーセプトロン No.i に入力される信号」
</b>
</p>

<p>
を表します。
</p>

<div class="info">
<input type="checkbox"><b>図1: 教師信号</b>

<p>
teacher : 教師信号、 L x N 行列 (<a href="../text01/page04.html#const">定数テンソル</a>)
</p>
<p>
※ $t_{\rm ji}$ ＝ 訓練データセット No.j の教師信号において入力層のパーセプトロン No.i に入力される信号
</p>


<img src="./img/page04-fig1.png" alt="">
</div>

<br>
<h3>
3. ラベル
</h3>

<p>
次はラベルについて考えます。
</p>

<p>
今考えている 3 層ニューラルネットワークの出力層のパーセプトロンの個数は M 個で、訓練データセットのサイズは L としましたので、 ラベル全体の名前を label とすると、label は LxM 行列
</p>

\[
{\rm label} = 
\begin{bmatrix}
l_{00}\ , & \cdots &,\  l_{\rm 0(M-1)} \\
\vdots & \ddots & \vdots \\
l_{\rm (L-1)0} \ , & \cdots &,\  l_{\rm (L-1)(M-1)} \\
\end{bmatrix}
\]

<p>
 で表すことができます。
</p>

<p>
さて、このラベルの値をどのように決めるかについては色々な形式があるのですが、今回は「<a href="https://ja.wikipedia.org/wiki/One-hot">one-hot ベクトル</a>形式」を使いたいと思います。
</p>

<p>
one-hot ベクトル形式とは、あるクラスに属する場合は 1、それ以外は 0 とする様にラベルを決める形式です。
</p>

<p>
例えばニューラルネットワークに入力された画像を「猫」と「犬」と「鳥」の 3 クラスに分類したい場合を考えてみましょう。
<br>
この場合は、M = 3 とし、訓練データセット No.j における教師信号が猫(クラス No.0 とします)の画像だったら $l_{j0} = 1$ 、犬の画像(クラス No.1 とします)だったら $l_{j1} = 1$ 、鳥の画像(クラス No.2 とします)だったら $l_{j2} = 1$ 、それ以外は 0 の値を label にセットします。
<br>
つまり
</p>

<p>
猫ラベル(クラス No.0)・・・ [1,0,0]
<br>
犬ラベル(クラス No.1)・・・ [0,1,0]
<br>
鳥ラベル(クラス No.2)・・・ [0,0,1]
</p>

<p>
とします。
</p>

<p>
この様に TensorFlow ではラベル label は図 2 の様に L x M 行列の<a href="../text01/page04.html#const">定数テンソル</a>で定義され、
</p>

<p>
<b>
「label の j 行 i 列目の値 $l_{\rm ji}$ は訓練データセット No.j の教師信号がクラス No.i に属してるか(=1)、属していないか(=0)」
</b>
</p>

<p>
を表します。
</p>

<div class="info">
<input type="checkbox"><b>図2: ラベル</b>

<p>
label : ラベル、 L x M 行列 (<a href="../text01/page04.html#const">定数テンソル</a>)、j 行目が訓練データセット No.j に相当
</p>

<p>
※ $l_{\rm ji}$ ＝ 訓練データセット No.j の教師信号がクラス No.i に属してるか(=1)、属していないか(=0)
</p>

<img src="./img/page04-fig2.png" alt="">

</div>

<br>
<h3>
4. 出力信号
</h3>

<p>
さて LxN 行列で定義した教師信号全体 teacher を 3 層ニューラルネットワークに入力すると、出てくる出力信号も行列になります。
<br>
出力信号全体の名前を predict とすると、predict は LxM 行列
</p>

\[
{\rm predict} = 
\begin{bmatrix}
p_{00}\ , & \cdots &,\  p_{\rm 0(M-1)} \\
\vdots & \ddots & \vdots \\
p_{\rm (L-1)0}\ , & \cdots &,\  p_{\rm (L-1)(M-1)} \\
\end{bmatrix}
\]

<p>
になります。
</p>

<p>
さて今回は出力層のパーセプトロンの活性化関数を<a href="../text01/page04.html#softmax">softmax 関数</a>としたため
</p>

<p>
\[
0 \leq p_{ji} \leq 1 \ ,\  \sum_{i=0}^{\rm M-1} p_{ji} = 1
\]
</p>

<p>
という関係が成り立っていますので、
</p>

<p>
<b>
「predict の j 行 i 列目の値 $p_{\rm ji}$ は訓練データセット No.j の教師信号がクラス No.i に属する予測確率」
</b>
</p>

<p>
を表します。
</p>

<br>
<h3>
5. 損失関数
</h3>

<p>
訓練データセットを用意したら、次は重みとバイアス( w_h、b_h、w_o、b_o の4つ)をディープラーニングを使って学習します。
</p>

<p>
ただし何らかの指標が無いと正しく学習されているか分かりませんので、まずその指標を決める必要があります。
<br>
この指標の事を「<b>損失関数</b>(loss function)」、損失関数の戻り値を「<b>損失</b>(loss)」と呼びます。
</p>

<p>
この損失関数には色々な種類がありますが、今回は多クラス分類問題でよく使われている「<b>カテゴリカル・クロスエントロピー</b>(categorical cross entropy)」を利用したいと思います。
<br>
カテゴリカル・クロスエントロピーは上で定義したラベル(label)と予想確率(predict)それぞれの要素 $l_{ji}$ と $p_{ji}$ を使って次の様に定義されます。
</p>

<div class="info">
<input type="checkbox"><b>定義: カテゴリカル・クロスエントロピーの定義</b>

<p>
\[
{\rm entropy} = -\sum_{j=0}^{\rm L-1} \sum_{i=0}^{M-1} l_{ji}\log p_{ji}
\]
</p>

<p>
※ 最後に -1 かけるのを良く忘れるので注意
</p>

</div>

<p>
上の式によって求められた値 entropy は
</p>

<ul>
<li><b>ラベル(label)と予測確率(predict)が似ていない → entropy は大</b></li>
<li><b>ラベル(label)と予測確率(predict)が似ている → entropy は小</b></li>
</ul>

<p>
というとても良い性質を持っていますので、entropy が可能な限り小さくなる様に重みとバイアスの値を学習させて更新すれば良い事が分かります。
</p>

<p>
ではこのカテゴリカル・クロスエントロピーを TensorFlow のデータフロー・グラフ化してみましょう。
<br>
上の定義式はは<a href="../text01/page04.html#redsum">総和演算</a>を使って次のような行列演算で表すことができます。
</p>

<div class="info">
<input type="checkbox"><b>カテゴリカル・クロスエントロピーの行列演算</b>
<p>
entropy = - reduce_sum( log(predict)*label )
</p>

<p>
※ 最後に -1 かけるのを良く忘れるので注意
</p>

</div>

<p>
従ってカテゴリカル・クロスエントロピーの演算をデータフロー・グラフ化すると次のようになります。
</p>

<div class="info">
<input type="checkbox"><b>図3: カテゴリカル・クロスエントロピーのデータフロー・グラフ(演算部のみ抜粋)</b>

<p>
<br>
予測確率 predict に<a href="../text01/page04.html#log">log</a> を通し、ラベル label と<a href="../text01/page04.html#mul">掛け合わせる</a>、さらに<a href="../text01/page04.html#redsum">総和演算</a>をして -1 倍して entropy に出力する
</p>

<img src="./img/page04-fig3.png" alt="">
</div>

<p>
predict を求めている 3 層ニューラルネットワーク部分も含めると、全体では次のようなデータフロー・グラフとなります。
</p>

<div class="info">
<input type="checkbox"><b>図4: カテゴリカル・クロスエントロピーのデータフロー・グラフ(全体)</b>

<p>　</p>

<img src="./img/page04-fig4.png" alt="">
</div>



<br>
<h3>
6. 最適化アルゴリズム
</h3>

<p>
次は重みやバイアスの具体的な学習方法について考えます。
</p>

<p>
損失が小さくなるように重みやバイアスを学習して更新するアルゴリズムを<b>最適化アルゴリズム</b>と呼びます。
<br>
最適化アルゴリズムには色々な種類があるのですが、今回は「<a href="https://ja.wikipedia.org/wiki/%E7%A2%BA%E7%8E%87%E7%9A%84%E5%8B%BE%E9%85%8D%E9%99%8D%E4%B8%8B%E6%B3%95">SGD</a>(Stochastic Gradient Descent: 確率的勾配降下法)」と「<b>Adam</b>(ADAptive Moment estimation)」の 2 つを取り扱います。
</p>

<p>
※ SGD はベーシックな最適化アルゴリズムなのでチュートリアルなどでは良く使われてるアルゴリズムなのですが、学習の収束速度が遅いことから、実際には Adam が使われることが多いようです。
</p>

<p>
この SGD や Adam を実行するためは非常に難しい数学の知識が必要なのですが、幸いなことに TensorFlow ではクラスとして既に用意されているので誰でも簡単に利用できます。
</p>

<div class="info">
<input type="checkbox"><b>SGD クラスと Adam クラス </b>

<p>
SGD クラス: tf.keras.optimizers.SGD( learning_rate=学習率 )
</p>

<p>
Adam クラス: tf.keras.optimizers.Adam( learning_rate=学習率 )
</p>

<p>
学習実行メソッド: minimize( lambda: 損失関数, [学習対象の変数のリスト] )・・・学習を1回実施する、戻り値は実施済み学習回数
</p>

</div>

<p>
ここで学習率(learning rate)は学習の精度と速度を表しています。
<br>
学習率の値が大きいほどニューラルネットワークは適当に学習しますが速く学習が進みます。
<br>
逆に値が小さいとニューラルネットワークはきちんと学習しますが遅く学習が進みます。
</p>

<p>
いずれにしろ 1 回では学習は終わりませんので、損失関数の値が十分小さくなるまで何回も学習を繰り返す必要があります。
</p>

<p>
例えば以下のソース 1 は Adam を用いた学習例です。
<br>
この例では学習対象である変数 x と y の初期値をそれぞれ 1,0 と-0.5、損失関数を ${\rm loss}() = x^2+y^2$、学習率を 0.1、学習回数を 50 回 としたとき、loss() の戻り値(損失)が最小になる x と y の値を Adam を使って求めています。
</p>

<div class="info">
<input type="checkbox"><b>ソース 1: Adam による学習例</b>

<pre class="wrap">
import tensorflow as tf

# 学習対象の変数
x = tf.Variable([[1]], dtype=tf.float32)
y = tf.Variable([[-0.5]], dtype=tf.float32)

#損失関数
@tf.function
def loss():
    return x**2 + y**2

print('損失='+str(loss().numpy()))
print('x='+str(x.numpy()))
print('y='+str(y.numpy()))
print('')

opt = tf.keras.optimizers.Adam( learning_rate=0.1 ) # Adamクラスのインスタンス
#opt = tf.keras.optimizers.SGD( learning_rate=0.1 ) # SGD を使いたい場合はこちら
for i in range(50):  # 学習を50回繰り返す
    opt.minimize(lambda: loss(), [x,y])
    
print('結果')
print('損失='+str(loss().numpy()))
print('x='+str(x.numpy()))
print('y='+str(y.numpy()))
print('')
</pre>
</div>

<p>
結果は以下のようになります。
<br>
学習を50回繰り返すと損失が十分小さくなり、 (x,y) の値が loss() を最小する (0,0) に近づいていることが分かります。
</p>

<div class="info">
<input type="checkbox"><b>ソース 1 の結果</b>

<pre class="wrap">
損失=[[1.25]]
x=[[1.]]
y=[[-0.5]]

結果
損失=[[0.0007694]]
x=[[-0.00481954]]
y=[[-0.02731619]]
</pre>
</div>

<br>
<h3>
7. ミニバッチ学習
</h3>

<p>
実際のディープラーニングでは訓練データセットのサイズ L は膨大な数となるため、訓練データセット全てを使って一気に学習を行うことは滅多にありません。
</p>

<p>
ではどうするかというと、訓練データセットを更に「<b>バッチ(batch)</b>」と呼ばれるサブ訓練データセットに細かく分割し、バッチ単位で学習を行います。
<br>
この学習方法のことを「<b>ミニバッチ学習</b>」といいます。
</p>

<p>
またバッチに含まれる教師信号とラベルの組の個数を「<b>バッチサイズ</b>」と呼び、慣習的には 32,64,128,256,・・・・ など 2 の n 乗の数が良く使われています。
</p>

<p>
さてバッチの分割方法も色々あるのですが、今回は単純に訓練データセットの先頭から順に取り出すことにします。
<br>
つまりバッチサイズを B としたとき、バッチ No.k の教師信号 teacher_batch_k は BxN 行列
</p>

\[
{\rm teacher\_batch\_k} =
\begin{bmatrix}
t_{(B*k)0} \ , & \cdots &,\  t_{\rm (B*k)(N-1)} \\
\vdots & \ddots & \vdots \\
t_{\rm (B*k+B-1)0}\ ,  & \cdots &,\  t_{\rm (B*k+B-1)(N-1)} \\
\end{bmatrix}
\]


<p>
ラベル label_batch_k は BxM 行列
</p>

\[
{\rm label\_batch\_k} =
\begin{bmatrix}
l_{(B*k)0} \ , & \cdots &,\  l_{\rm (B*k)(M-1)} \\
\vdots & \ddots & \vdots \\
l_{\rm (B*k+B-1)0}\ ,  & \cdots &,\  l_{\rm (B*k+B-1)(M-1)} \\
\end{bmatrix}
\]

<p>
となります。
</p>

<p>
ところで訓練データセットのサイズは L でしたのでバッチは総数 L/B 個あります( L が B で割り切れない場合は今回は考えないことにします)。
<br>
バッチ No.0 から順にバッチ No.(L/B)-1 まで全てのバッチを使って一通り学習を済ませることを「<b>エポック</b>(epoch)」と呼び、エポックの繰り返し回数のことを「<b>エポック数</b>」と呼びます。
</p>

<p>
用語だけ書いてもなかなか分かりにくいのですが、例えばエポック数が 3 のときは次のようにして学習が行われます。
</p>

<p>
学習開始
<br>
→ (エポック 0 開始) パッチNo.0を使って学習 → ・・・ → パッチNo.(L/B)-1 を使って学習 (エポック 0 終了) 
<br>
→ (エポック 1 開始) パッチNo.0を使って学習 → ・・・ → パッチNo.(L/B)-1 を使って学習 (エポック 1 終了) 
<br>
→ (エポック 2 開始) パッチNo.0を使って学習 → ・・・ → パッチNo.(L/B)-1 を使って学習 (エポック 2 終了) 
<br>
3回エポックを繰り返したので学習終了
</p>

<br>
<h3>
8. ディープラーニングの実行
</h3>

<p>
では全ての準備が整ったのでいよいよディープラーニングを実行してみましょう。
</p>

<p>
今回考えている 3 層ニューラルネットワークの場合、学習対象の変数は w_h、b_h、w_o、b_o の4つですので、結局のところ次のように書けばディープラーニングが実行されます。
</p>

<div class="info">
<input type="checkbox"><b>ソース 2: 3 層ニューラルネットワークのディープラーニング</b>

<pre class="wrap">
opt = tf.keras.optimizers.Adam( learning_rate=r ) # 最適化アルゴリズムは Adam
#opt = tf.keras.optimizers.SGD( learning_rate=r ) # SGD を使いたい場合はこちら
for e in range(E):
    for k in range(int(L/B)):
        print('\repoch '+str(e)+' batch '+str(k), end='')
        teacher_batch_k = teacher[B*k:B*k+B]
        label_batch_k = label[B*k:B*k+B]
        opt.minimize(lambda: loss(teacher_batch_k,label_batch_k), [w_h,b_h,w_o,b_o])

※1 r : 学習率
※2 E : エポック数
※3 L : 訓練データセットのサイズ
※4 B : バッチサイズ
※5 teacher, label : 教師信号全体とラベル全体、
※6 w_h, b_h, w_o, b_o : 隠れ層の重み、隠れ層のバイアス、出力層の重み、出力層のバイアス
※7 loss(教師信号,ラベル) : カテゴリカル・クロスエントロピーを計算している損失関数
</pre>
</div>


<br>
<h3>
9. 検証データセットとテストデータセット
</h3>

<p>
いままでは訓練データセットだけを考えていましたが、実際にディープラーニングを実行する場合は「<b>検証データセット</b>」と「<b>テストデータセット</b>」というデータセットも必要です。
</p>

<p>
検証データセットは訓練データセットの様に検証用入力データとそれに対応するラベルが組になっているデータセットです。
<br>
同様にテストデータセットもテスト用入力データとそれに対応するラベルが組になっているデータセットです。
</p>

<p>
何が違うのか疑問に思うかもしれませんが
</p>

<ul>
<li><b>検証データセット ・・・学習中に正しく学習されてるか途中チェック用に繰り返し使う(学習用には使わない)</b></li>
<li><b>テストデータセット・・・学習が終わってから、最終チェック用として最後に1回だけ使う(学習中は使わない)</b></li>
</ul>

<p>
という違いがあります。
</p>

<p>
訓練データセットだけ使って評価してしまうと「<a href="https://ja.wikipedia.org/wiki/%E9%81%8E%E5%89%B0%E9%81%A9%E5%90%88">過学習</a>(オーバーフィッティング)」が生じてしまい、実際のデータに適合していないモデルが出来てしまうことがあります。
</p>

<p>
そこで検証データセットも学習中に併用し、過学習が起きてないか(つまり訓練データセットだと損失が小さいけど検証データセットだと損失が大きい状況)常に確認しながら学習を進める必要があります。
<br>
もし過学習が生じてしまっている場合は、パラメータの数を見直したり、場合によってはモデルそのものを見直して最初から学習をやり直す必要があります。
</p>

<p>
さらに、訓練データセットと検証データセットを使って上手く学習を終えたとしても、テストデータセットの損失が大きい場合は最終チェックに不合格ということですので、これまたパラメータの数やモデルを見直して最初から学習をやり直す必要があります。
</p>

<br>
<h3>
10. 評価関数
</h3>

<p>
学習自体は上で説明した損失関数を使うのですが、損失関数が返す値は人間には分かりにくいという欠点があります。
<br>
そこで人間が評価しやすいように、損失関数とは別に「<b>評価関数</b>(metric function)」を損失関数と併用して学習結果を評価する場合があります。
</p>

<p>
損失関数と同じ様に評価関数にも色々な種類がありますが、今回は「<b>正解率</b>(accuracy)」を利用します。
<br>
正解率の計算方法も色々ありますが、今回の様に多クラス分類問題、かつラベルが one-hot ベクトル形式の場合は以下のソース 3 で示した関数によって計算できます。
</p>

<p>
※ 評価関数は学習には関係ないので TensorFlow を使わないで普通に numpy を使っています
</p>

<div class="info">
<input type="checkbox"><b>ソース 3: 正解率(カテゴリカルデータ用) </b>

<pre class="wrap">
def categorical_accuracy(predict,label):
    predict_amax = np.argmax(predict.numpy(),axis=1)
    label_amax = np.argmax(label.numpy(),axis=1)
    equal = np.equal(predict_amax, label_amax)
    return np.mean(equal)

※1 predict: 学習・検証・テストデータセットから求めた予測確率
※2 label : 正しいラベル (one-hot ベクトル形式)
</pre>
</div>


<br>
<script>PreNext(4,5)</script>
</body>
</html>
