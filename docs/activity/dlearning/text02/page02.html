<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1.0">
<link rel="stylesheet" href="../../../common.css">
<script src="../../../common.js"></script>
<script src="../../../mathjax.js"></script>
<title>2. 多層ニューラルネットワーク</title>
</head>
<body>

<nav class="brcr">
<ol>
<li><a href="../">アクティビティ: TensorFlow によるディープラーニング</a></li>
<li>学習項目: [2] ディープラーニングの基本</li>
<li><script>GetTitle()</script></li>
</ol>
</nav>

<h2><script>GetTitle()</script></h2>

<h3>
1. パーセプトロン
</h3>

<p>
生物学で学んだように、動物の脳は多数(人間の大脳の場合140億個位)の「神経細胞」という細胞がシナプス結合されて出来ています。
<br>
そこでまず数学者はこの「神経細胞」を数学的にモデル化した「<b>パーセプトロン</b>」を考案しました。
</p>

<p>
パーセプトロンは $n$ 入力信号 - $1$ 出力信号の関数 $f()$ であり、以下の数式で表すことができます。
</P>

<div class="info">
<input type="checkbox"><b>定義: パーセプトロンの式:</b>

\begin{align*}
y &= f \left ( \sum_{i=1}^{n} \{w_i\cdot x_i\} + b  \right )  \\
&= f \left ( w_1\cdot x_1 + \cdots + w_n\cdot x_n + b  \right ) 
\end{align*}

<p>
$y$ : 出力信号
</p>
<p>
$x_i$ : $i$ 番目の入力信号、 $(i=1,2,\cdots,n)$
</p>
<p>
$w_i$ : $i$ 番目の入力信号に掛けられる<b>重み</b>(weight)
</p>
<p>
$b$ : <b>バイアス</b>
</p>

</div>

<p>
また関数 $f()$ の事を正式には「活性化関数」といいます。
<br>
活性化関数の選び方には色々な流儀があるのですが、今回のアクティビティでは良く使われている「<a href="https://en.wikipedia.org/wiki/Sigmoid_function">シグモイド関数</a>」と「<a href="https://en.wikipedia.org/wiki/Softmax_function">SoftMax関数</a>」を用いたいと思います。
</p>

<p>
$w_i$ と $b$ は変数なので値は自由に決めても良いのですが、普通はディープラーニングを使って値を決めます。
<br>
詳しくは<a href="./page04.html">ディープラーニングのページ</a>で説明します。
</p>

<p>
さてパーセプトロンは以下の様なグラフで表すことが出来ます。
<br>
なお、このグラフは前の学習項目で学んだ「<a href="../text01/page03.html">データフローグラフ</a>」とは異なる一般的なグラフです。
<br>
つまりこの図の○はOPノードではなくて活性化関数 $f()$ を表しています。
</p>

<div class="info">
<input type="checkbox"><b>図1. パーセプトロンのグラフ:</b>

<img src="./img/page02-fig1.png" alt="">
</div>


<br>
<h3>
2. 多層ニューラルネットワーク
</h3>

<p>
次に数学者は「パーセプトロン」を多数結合して「<b>多層ニューラルネットワーク</b>」(「多層構造ニューラルネットワーク」とか「多層パーセプトロン」などとも呼ばれることもあります)を作りました。
</p>

<p>
多層ニューラルネットワークは「<b>入力層</b>」、「<b>隠れ層</b>(中間層とも言う)」、「<b>出力層</b>」ごとに層(レイヤー)分けされた多層構造になっています(図2)。
<br>
「入力層」、「出力層」は 1 層構造ですが、「隠れ層」は 2 層以上の多層構造になる場合もあります。
<br>
いずれにしろ、各層は多数のパーセプトロンが結合されて出来ています。
<br>
なおパーセプトロンの事を「<b>ユニット</b>」と呼ぶこともあります。
</p>


<div class="info">
<input type="checkbox"><b>図2. 多層ニューラルネットワークのグラフ:</b>

<p>
多数のパーセプトロン(ユニット)が階層状に結合されて出来ている
</p>

<img src="./img/page02-fig2.png" alt="">
</div>

<p>
ただしあまり隠れ層の層数を増やすとディープラーニングに必要な時間が膨大になりますので、今回のアクティビティでは中間層が 1 層だけで出来ている 3 層ニューラルネットワークを扱いたいと思います(図3)。


<div class="info">
<input type="checkbox"><b>図3. 3層ニューラルネットワークのグラフ:</b>

<p>
入力層が N 個、隠れ層(1層)が K 個、出力層が M 個のパーセプトロンで出来ているネットワーク
</p>

<p>
パラメータ:
</p>

<p>
$w_{ij}^{\textrm h}$ ・・・ 入力層のパーセプトロン No.$i$ の出力信号から、隠れ層のパーセプトロン No.$j$ への入力に掛けられる重み
</p>
<p>
$b_{j}^{\textrm h}$  ・・・ 隠れ層のパーセプトロン No.$j$ のバイアス
</p>

<p>
および
</p>

<p>
$w_{ij}^{\textrm o}$ ・・・ 隠れ層のパーセプトロン No.$i$ の出力信号から、出力層のパーセプトロン No.$j$ への入力に掛けられる重み
</p>
<p>
$b_{j}^{\textrm o}$  ・・・ 出力層のパーセプトロン No.$j$ のバイアス
</p>

<img src="./img/page02-fig3.png" alt="">
</div>

<br>

<script>PreNext(2,5)</script>
</body>
</html>
