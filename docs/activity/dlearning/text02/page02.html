<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1.0">
<link rel="stylesheet" href="../../../common.css">
<script src="../../../common.js"></script>
<script src="../../../mathjax.js"></script>
<title>2. 3層ニューラルネットワーク</title>
</head>
<body>

<nav class="brcr">
<ol>
<li><a href="../">アクティビティ: TensorFlow によるディープラーニング</a></li>
<li>学習項目: [2] ディープラーニングの基本</li>
<li><script>GetTitle()</script></li>
</ol>
</nav>

<h2><script>GetTitle()</script></h2>

<h3>
1. パーセプトロン
</h3>

<p>
動物の脳は多数(人間の大脳の場合140億個位)の「<b>神経細胞</b>」という細胞がシナプス結合されて出来ています。
<br>
そこでまず数学者はこの「神経細胞」を数学的にモデル化した「<b>パーセプトロン</b>」を考案しました。
</p>

<p>
なお文献によってはパーセプトロンの事を「<b>ユニット</b>」や「<b>ノード</b>」と呼ぶこともあります。
</p>

<p>
さてパーセプトロンは $n$ 個の入力信号に対し 1 個の信号を出力する関数 $f()$ であり、以下の数式で表すことができます。
</P>

<p>
この $f()$ の事を「<a href="https://ja.wikipedia.org/wiki/%E6%B4%BB%E6%80%A7%E5%8C%96%E9%96%A2%E6%95%B0">活性化関数</a>」と呼びます。
</p>

<div class="info">
<input type="checkbox"><b>定義: パーセプトロンの式:</b>

\begin{align*}
y &= f \left ( \sum_{i=0}^{n-1} \{w_i\cdot x_i\} + b  \right )  \\
&= f \left ( w_0\cdot x_0 + \cdots + w_{(n-1)}\cdot x_{(n-1)} + b  \right ) 
\end{align*}

<p>
$y$ : 出力信号
</p>
<p>
$f()$ : 活性化関数
</p>
<p>
$x_i$ : $i$ 番目の入力信号、 $(i=0,1,\cdots,n-1)$
</p>
<p>
$w_i$ : 変数、$i$ 番目の入力信号に掛けられる<b>重み</b>(weight)と呼ぶ
</p>
<p>
$b$ : 変数、<b>バイアス</b>(bias)と呼ぶ
</p>

</div>

<p>
活性化関数 $f()$ の選び方には色々な流儀があるのですが、世間的には「<a href="https://ja.wikipedia.org/wiki/%E3%82%B7%E3%82%B0%E3%83%A2%E3%82%A4%E3%83%89%E9%96%A2%E6%95%B0">sigmoid 関数</a>」、「<a href="https://ja.wikipedia.org/wiki/%E5%8F%8C%E6%9B%B2%E7%B7%9A%E9%96%A2%E6%95%B0">双曲線正接(tanh)関数</a>」、「<a href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)">ReLU (Rectified linear Unit)</a>」、「<a href="https://en.wikipedia.org/wiki/Softmax_function">softmax 関数</a>」などが良く使われています。
</p>

<p>
なおパーセプトロンは以下の様なグラフで表すことが出来ます。
<br>
ただしこのグラフは TensorFlow の<a href="../text01/page03.html">データフロー・グラフ</a>とは異なる一般的なグラフです。
<br>
つまりこの図の○はオペレーションではなくて活性化関数 $f()$ を表しています。
</p>

<div class="info">
<input type="checkbox"><b>図1. パーセプトロンのグラフ</b>

<p>
※ <a href="../text01/page03.html">データフロー・グラフ</a>ではなくて一般的なグラフ表現です
</p>

<img src="./img/page02-fig1.png" alt="">
</div>


<br>
<h3>
2. 多層パーセプトロン(MLP)
</h3>

<p>
次に数学者は「パーセプトロン」を多数結合して「<a href="https://ja.wikipedia.org/wiki/%E5%A4%9A%E5%B1%A4%E3%83%91%E3%83%BC%E3%82%BB%E3%83%97%E3%83%88%E3%83%AD%E3%83%B3">多層パーセプトロン</a>(通称 <b>MLP</b>: Multi-Layer Perceptron)」と呼ばれるネットワークを考えました。
</p>

<p>
MLP は「<b>入力層</b>」、「<b>隠れ層</b>(中間層とも言う)」、「<b>出力層</b>」ごとに層(レイヤー)分けされた多層構造になっています。
</p>

<p>
なお MLP の各層は 2 層以上の多層構造になったり、再帰構造になったりすることもありますが、今回は話を簡単にするために再帰構造を含まない MLP だけを考えることにします。
<br>
再帰構造を含まない MLP のことを一般に「<b>フィードフォワードニューラルネットワーク</b>」と呼んでいます(図 2)。
</p>

<div class="info">
<input type="checkbox"><b>図2. フィードフォワードニューラルネットワークのグラフ</b>


<p>
※ <a href="../text01/page03.html">データフロー・グラフ</a>ではなくて一般的なグラフ表現です
</p>

<img src="./img/page02-fig2.png" alt="">
</div>

<br>
<h3>
3. 3層ニューラルネットワーク
</h3>

<p>
さらに話を簡単にするため、今回は中間層が 1 層だけで出来ている 3 層ニューラルネットワークを扱いたいと思います(図3)。
</p>

<p>
※ 正確には「3 層フィードフォワードニューラルネットワーク」ですが、長いので単に「3層ニューラルネットワーク」とだけ書きます
</p>


<div class="info">
<input type="checkbox"><b>図3. 3層ニューラルネットワークのグラフ</b>

<p>
※ <a href="../text01/page03.html">データフロー・グラフ</a>ではなくて一般的なグラフ表現です
</p>


<p>
入力層が N 個、隠れ層が K 個、出力層が M 個のパーセプトロンで出来ているフィードフォワードニューラルネットワーク
</p>

<img src="./img/page02-fig3.png" alt="">

<p>
$w_{ij}^{\textrm h}$ ・・・ 入力層のパーセプトロン No.$i$ の出力信号から、隠れ層のパーセプトロン No.$j$ への入力に掛けられる重み
</p>
<p>
$b_{j}^{\textrm h}$  ・・・ 隠れ層のパーセプトロン No.$j$ のバイアス
</p>

<p>
および
</p>

<p>
$w_{ij}^{\textrm o}$ ・・・ 隠れ層のパーセプトロン No.$i$ の出力信号から、出力層のパーセプトロン No.$j$ への入力に掛けられる重み
</p>
<p>
$b_{j}^{\textrm o}$  ・・・ 出力層のパーセプトロン No.$j$ のバイアス
</p>

</div>

<br>

<script>PreNext(2,5)</script>
</body>
</html>
