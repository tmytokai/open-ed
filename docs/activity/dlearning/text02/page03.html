<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1.0">
<link rel="stylesheet" href="../../../common.css">
<script src="../../../common.js"></script>
<script src="../../../mathjax.js"></script>
<title>3. 3層ニューラルネットワークのデータフロー・グラフ化</title>
</head>
<body>

<nav class="brcr">
<ol>
<li><a href="../">アクティビティ: TensorFlow によるディープラーニング</a></li>
<li>学習項目: [2] ディープラーニングの基本</li>
<li><script>GetTitle()</script></li>
</ol>
</nav>

<h2><script>GetTitle()</script></h2>

<p>
では<a href="./page02.html">前ページ</a>で説明した 3 層ニューラルネットワークのグラフを TensorFlow の<a href="../text01/page03.html">データフロー・グラフ</a>に変換してみましょう。
</p>

<br>
<h3>
1. 入力信号
</h3>

<p>
まず入力信号を考えます。
</p>

<p>
入力層は N 個のパーセプトロンで出来ていて、N 個の信号が入力されます。
<br>
ただ信号はただの数値の羅列ですので、入力信号は結局のところ 1 x N 行列の<a href="../text01/page04.html#const">定数テンソル</a> (※)になります(図1)。
<br>
今回は data という名前のテンソルとします。
</p>

<div class="info">
<input type="checkbox"><b>図1: 入力信号</b>

<p>
data : 入力信号、 1 x N 行列 (<a href="../text01/page04.html#const">定数テンソル</a>)
<br>

<img src="./img/page03-fig1.png" alt="">
</div>

<br>
<h3>
2. 入力層
</h3>

<p>
次に入力層を考えます。
</p>

<p>
<a href="./img/page02-fig3.png">前ページの図3</a>から入力層だけを切り出したのが以下の図2です。
</p>

<div class="info">
<input type="checkbox"><b>図2: 入力層のグラフ:</b>

<p>
※ <a href="../text01/page03.html">データフロー・グラフ</a>ではなくて一般的なグラフ表現です
</p>

<img src="./img/page03-fig2.png" alt="">
</div>


<p>
この様に、入力層は入力されたデータをそのままスルーして出力するだけなので、データフロー・グラフは図3の様になります。
</p>

<div class="info">
<input type="checkbox"><b>図3: 入力層 のデータフローグラフ</b>

<p>
入力信号 data をスルーして隠れ層にそのまま渡すだけ(つまり何もしない)
</p>

<img src="./img/page03-fig3.png" alt="">
</div>

<br>
<h3>
3. 隠れ層
</h3>

<p>
次に隠れ層を考えます。
</p>

<p>
<a href="./img/page02-fig3.png">前ページの図3</a>から(入力層と)隠れ層を切り出したのが以下の図4です。
</p>

<div class="info">
<input type="checkbox"><b>図4: 隠れ層のグラフ</b>

<p>
※ <a href="../text01/page03.html">データフロー・グラフ</a>ではなくて一般的なグラフ表現です
</p>

<img src="./img/page03-fig4.png" alt="">

<p>
$w_{ij}^{\textrm h}$ ・・・ 入力層のパーセプトロン No.$i$ の出力信号から、隠れ層のパーセプトロン No.$j$ への入力に掛けられる重み
</p>
<p>
$b_{j}^{\textrm h}$  ・・・ 隠れ層のパーセプトロン No.$j$ のバイアス
</p>

</div>

<p>
隠れ層は K 個のパーセプトロンで出来ていて、それぞれのパーセプトロンは入力層からの出力信号を受取ります。
その際に重みが入力に掛けられ、更にバイアスが足されます。そして最後に活性化関数 $f()$ に通して出力されます。
</p>

<p>
$x_i$ を入力層のパーセプトロン No.$i$ からの出力信号とし、活性化関数 $f()$ を全てのパーセプトロンで共通とすると、隠れ層のパーセプトロン No.$j$ の出力 $y_j^{\textrm h}$ は以下の式で表されます。
</p>

<p>
\[
y_j^{\textrm h} = f \left ( \sum_{i=1}^{N} \{w_{ij}^{\textrm h}\cdot x_i\} + b_j^{\textrm h}  \right ) \ , \ (j=1,2,\cdots,K)
\]
</p>

<p>
さて入力層のパーセプトロンは N 個、隠れ層のパーセプトロンは K 個ありますので、それらの出力を行列で表すと次のようになります。
</p>

<p>
入力層の出力:
\[
X = [x_1, x_2, \cdots, x_N]
\]
</p>

<p>
隠れ層の出力:
\[
Y^{\textrm h} = [y_1^{\textrm h}, y_2^{\textrm h}, \cdots, y_K^{\textrm h}]
\]
</p>

<p>
また重み $w_{ij}^{\textrm h}$ は N x K 行列、バイアス $b_{j}^{\textrm h}$ は 1 x K 行列で表すことができます。
</p>

<p>
重み:
\[
W^{\textrm h} = 
\left [
\begin{array}{ccc}
w_{11}^{\textrm h} & \cdots & w_{1K}^{\textrm h} \\
\vdots & \ddots & \vdots \\
w_{N1}^{\textrm h} & \cdots & w_{NK}^{\textrm h}
\end{array}
\right ]
\]
</p>

<p>
バイアス:
\[
B^{\textrm h} = 
[b_1^{\textrm h}, b_2^{\textrm h}, \cdots, b_K^{\textrm h}]
\]
</p>

<p>
以上の行列を使うと、隠れ層の出力 $Y^{\textrm h}$ は以下の行列演算で求められます。なお $X\cdot W^{\textrm h}$ は $X$ と $W^{\textrm h}$ の行列積、$f()$ は行列の全て要素に対して活性化関数の演算を行う事を意味します。
</p>

<p>
\[
Y = f \left ( X\cdot W^{\textrm h} + B^{\textrm h} \right )
\]
</p>

<p>
ではこの行列演算を元に隠れ層を<a href="../text01/page03.html">データフロー・グラフ</a>化してみましょう。
</p>

<p>
まず重みとバイアスは後でディープラーニングを実行した際に値が変化しますので、定数テンソルではなく<a href="../text01/page04.html#var">変数テンソル</a> として定義します(図5)。
<br>
今回はそれぞれ w_h と b_h という名前のテンソルとします(h は hidden の意味)。
</p>


<div class="info">
<input type="checkbox"><b>図5: 隠れ層の重みとバイアス</b>

<p>
w_h : 隠れ層の重み、 N x K 行列 (<a href="../text01/page04.html#var">変数テンソル</a>)
</p>

<p>
b_h : 隠れ層のバイアス、1 x K 行列 (<a href="../text01/page04.html#var">変数テンソル</a>)
</p>

<p>
※ w_h と b_h の各要素は乱数で初期化する
</p>

<img src="./img/page03-fig5.png" alt="">
</div>

<p>
次に隠れ層を<a href="../text01/page03.html">データフロー・グラフ</a>化します。
<br>
活性化関数 $f()$ の選び方には色々な流儀がありますが、今回は<a href="../text01/page04.html#log">シグモイド(sigmoid)関数</a>を使いたいと思います。
<br>
すると隠れ層は図 6 のようなデータフロー・グラフになります。
</p>

<div class="info">
<input type="checkbox"><b>図6: 隠れ層のデータフロー・グラフ</b>

<p>
入力層からの出力信号( = 入力信号) data と w_h の<a href="../text01/page04.html#matmul">行列積</a> data・w_h を求め、それに b_h を<a href="../text01/page04.html#add">足し</a>、<a href="../text01/page04.html#log">シグモイド関数</a>に通して y_h に出力する
</p>


<img src="./img/page03-fig6.png" alt="">
</div>

<h3>
4. 出力層
</h3>

<p>
最後に出力層を考えます。
</p>

<p>
<a href="./img/page02-fig3.png">前ページの図3</a>から(隠れ層と)出力層を切り出したのが以下の図4です。
</p>

<div class="info">
<input type="checkbox"><b>図7: 出力層のグラフ:</b>

<p>
※ <a href="../text01/page03.html">データフロー・グラフ</a>ではなくて一般的なグラフ表現です
</p>

<img src="./img/page03-fig7.png" alt="">

<p>
$w_{ij}^{\textrm o}$ ・・・ 隠れ層のパーセプトロン No.$i$ の出力信号から、出力層のパーセプトロン No.$j$ への入力に掛けられる重み
</p>
<p>
$b_{j}^{\textrm o}$  ・・・ 出力層のパーセプトロン No.$j$ のバイアス
</p>

</div>

<p>
出力層は M 個のパーセプトロンで出来ていて、それぞれのパーセプトロンは隠れ層からの出力信号を受取ります。
<br>
その際に重みが入力に掛けられ、更にバイアスが足されます。
<br>
そして最後に活性化関数 $f()$ に通して出力されます。
</p>

<p>
つまりパーセプトロンの数と活性化関数が異なるだけで、出力層も隠れ層と同じ様な構造となります。
</p>

<p>
そこで出力層の重みとバイアスも<a href="../text01/page04.html#var">変数テンソル</a> として定義します(図8)。
<br>
今回はそれぞれ w_o と b_o という名前のテンソルとします(o は output の意味)。
</p>

<div class="info">
<input type="checkbox"><b>図8: 出力層の隠れ層の重みとバイアス</b>

<p>
w_o : 出力層の重み、 K x M 行列 (<a href="../text01/page04.html#var">変数テンソル</a>)
</p>

<p>
b_o : 出力層のバイアス、1 x M 行列 (<a href="../text01/page04.html#var">変数テンソル</a>)
</p>

<p>
※ w_o と b_o の各要素は乱数で初期化する
</p>

<img src="./img/page03-fig8.png" alt="">
</div>

<p>
出力層のデータフロー・グラフは図 9 となります。
<br>
活性化関数 $f()$ の選び方には色々な流儀がありますが、今回のアクティビティでは<a href="../text01/page04.html#softmax">softmax 関数</a>を使います。
</p>

<div class="info">
<input type="checkbox"><b>図9: 出力層のデータフロー・グラフ</b>

<p>
隠れ層からの出力信号 y_h と w_o の<a href="../text01/page04.html#matmul">行列積</a> y_h・w_oを求め、それに b_o を<a href="../text01/page04.html#add">足し</a>、<a href="../text01/page04.html#softmax">softmax 関数</a>に通し、y_o に代入する
</p>

<img src="./img/page03-fig9.png" alt="">
</div>

<br>
<h3>
5. 全体のデータフロー・グラフ
</h3>

<p>
以上の各層のデータフロー・グラフを組み合わせると、3層ニューラルネットワーク全体では次のようなデータフロー・グラフとなります。
</p>

<div class="info">
<input type="checkbox"><b>図10: 3層ニューラルネットワーク全体のデータフロー・グラフ</b>

<img src="./img/page03-fig10.png" alt="">
</div>


<br>
<script>PreNext(3,5)</script>
</body>
</html>
