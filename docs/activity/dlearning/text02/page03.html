<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1.0">
<link rel="stylesheet" href="../../../common.css">
<script src="../../../common.js"></script>
<script src="../../../mathjax.js"></script>
<title>3. TensorFlowによるMLPの構築</title>
</head>
<body>

<nav class="brcr">
<ol>
<li><a href="../">アクティビティ: TensorFlow/Keras によるディープラーニング</a></li>
<li>学習項目: [2] TensorFlow を用いた MLP の学習</li>
<li><script>GetTitle()</script></li>
</ol>
</nav>

<h2><script>GetTitle()</script></h2>

<p>
では<a href="./page02.html">前ページ</a>で説明した 3 層ニューラルネットワークを、<a href="../text01/page03.html">データフロー・グラフ</a>を使って TensorFlow で構築してみましょう。
</p>

<br>
<h3>
1. 入力信号
</h3>

<p>
まず入力信号を考えます。
</p>

<p>
入力信号全体の名前を data とすると、今考えている 3 層ニューラルネットワークの入力層のパーセプトロンの個数は N 個でしたので、 data は実数の 1xN 行列
</p>


\[
{\rm data} = 
\begin{bmatrix}
d_{0}\ , & \cdots &, d_{N-1} \\
\end{bmatrix}
\]

<p>
で表すことができます。
<br>
data の i 列目の値 $d_i$ が入力層のパーセプトロン No.i に入力される信号になります。
</p>

<p>
よって TensorFlow では入力信号は図 1 の様に 1 x N 行列の<a href="../text01/page04.html#const">定数テンソル</a>で定義されます。
</p>

<div class="info">
<input type="checkbox"><b>図1: 入力信号</b>

<p>
data : 入力信号、 1 x N 行列 (<a href="../text01/page04.html#const">定数テンソル</a>)
<br>

<img src="./img/page03-fig1.png" alt="">
</div>

<br>
<h3>
2. 入力層
</h3>

<p>
次に入力層を考えます。
</p>

<p>
<a href="./img/page02-fig3.png">前ページの図3</a>から入力層だけを切り出したのが以下の図2です。
</p>

<div class="info">
<input type="checkbox"><b>図2: 入力層のグラフ:</b>

<p>
※ <a href="../text01/page03.html">データフロー・グラフ</a>ではなくて一般的なグラフ表現です
</p>

<img src="./img/page03-fig2.png" alt="">
</div>


<p>
この様に、入力層は入力されたデータをそのままスルーして出力するだけなので、データフロー・グラフは図3の様になります。
</p>

<div class="info">
<input type="checkbox"><b>図3: 入力層 のデータフローグラフ</b>

<p>
入力信号 data をスルーして隠れ層にそのまま渡すだけ(つまり何もしない)
</p>

<img src="./img/page03-fig3.png" alt="">
</div>

<br>
<h3>
3. 隠れ層
</h3>

<p>
次に隠れ層を考えます。
</p>

<p>
<a href="./img/page02-fig3.png">前ページの図3</a>から(入力層と)隠れ層を切り出したのが以下の図4です。
</p>

<div class="info">
<input type="checkbox"><b>図4: 隠れ層のグラフ</b>

<p>
※ <a href="../text01/page03.html">データフロー・グラフ</a>ではなくて一般的なグラフ表現です
</p>

<img src="./img/page03-fig4.png" alt="">

<p>
$w_{ij}^{\rm h}$ ・・・ 入力層のパーセプトロン No.$i$ の出力信号から、隠れ層のパーセプトロン No.$j$ への入力に掛けられる重み
</p>
<p>
$b_{j}^{\rm h}$  ・・・ 隠れ層のパーセプトロン No.$j$ のバイアス
</p>

</div>

<p>
隠れ層は K 個のパーセプトロンで出来ていて、それぞれのパーセプトロンは入力層からの出力信号を受取ります。
<br>
その際に重みが入力に掛けられ、更にバイアスが足されます。そして最後に活性化関数 $f()$ に通して出力されます。
</p>

<p>
さて入力層はニューラルネットワークへの入力信号をそのままスルーしてただけですので、入力層からの出力信号全体は 1xN 行列

\[
{\rm data} = 
\begin{bmatrix}
d_{0}\ , & \cdots &,\  d_{N-1} \\
\end{bmatrix}
\]

<p>
となります。
</p>

<p>
よって出力層のパーセプトロン No.$i$ から出力される信号もそのまま $d_i$ となりますので、隠れ層のパーセプトロン No.$j$ の出力 $y_j^{\rm h}$ は以下の式で表されます。
</p>

<p>
\[
y_j^{\rm h} = f \left ( \sum_{i=0}^{\rm N-1} \{w_{ij}^{\rm h}\cdot d_i\} + b_j^{\rm h}  \right ) \ , \ (j=0,1,\cdots,{\rm K-1})
\]
</p>

<p>
次にこの式を行列の形に書き直します。
</p>

<p>
まず隠れ層の出力信号全体を表す行列を y_h とすると、y_h は 1xK 行列
</p>

\[
{\rm y\_h} = [y_0^{\rm h}\ , \cdots,\  y_{\rm K-1}^{\rm h}]
\]

<p>
隠れ層の重み全体を表す行列を w_h とすると、w_h は NxK 行列
</p>

<p>
\[
{\rm w\_h} = 
\begin{bmatrix}
w_{00}^{\rm h}\ , & \cdots &,\  w_{\rm 0(K-1)}^{\rm h} \\
\vdots & \ddots & \vdots \\
w_{\rm (N-1)0}^{\rm h}\ , & \cdots &,\  w_{\rm (N-1)(K-1)}^{\rm h}
\end{bmatrix}
\]
</p>

<p>
隠れ層のバイアス全体を表す行列を b_h とすると、b_h は 1xK 行列
</p>

\[
{\rm b\_h} = 
[b_0^{\rm h}\ , \cdots,\  b_{\rm K-1}^{\rm h}]
\]

<p>
で表されます。
</p>

<p>
また活性化関数 $f()$ には色々な種類がありますが、今回の例では<a href="../text01/page04.html#log">双曲線正接(tanh)関数</a>を使いたいと思います。
</p>

<p>
よって隠れ層の出力信号は以下の行列演算で求められます。
<br>
ここで ・ は行列積で、tanh(x) は行列の全ての要素に対して演算を行います。
</p>

<div class="info">
<input type="checkbox"><b>隠れ層の出力信号の行列演算</b>
   <p>
y_h = tanh( data・w_h + b_h )
</p>
</div>

<p>
ではこの行列演算を元に隠れ層を<a href="../text01/page03.html">データフロー・グラフ</a>化してみましょう。
</p>

<p>
まず重み w_h とバイアス b_h は<a href="./page04.html">次のページ</a>でディープラーニングを実行する際に値が変化しますので、定数テンソルではなく<a href="../text01/page04.html#var">変数テンソル</a> として定義します(図5)。
</p>


<div class="info">
<input type="checkbox"><b>図5: 隠れ層の重みとバイアス</b>

<p>
w_h : 隠れ層の重み、 N x K 行列 (<a href="../text01/page04.html#var">変数テンソル</a>)
</p>

<p>
b_h : 隠れ層のバイアス、1 x K 行列 (<a href="../text01/page04.html#var">変数テンソル</a>)
</p>

<p>
※ w_h と b_h の各要素は乱数で初期化する
</p>

<img src="./img/page03-fig5.png" alt="">
</div>

<p>
すると隠れ層は上で挙げた行列演算の式より図 6 のようなデータフロー・グラフになります。
</p>

<div class="info">
<input type="checkbox"><b>図6: 隠れ層のデータフロー・グラフ</b>

<p>
入力層からの出力信号( = 入力信号) data と w_h の<a href="../text01/page04.html#matmul">行列積</a> data・w_h を求め、それに b_h を<a href="../text01/page04.html#add">足し</a>、<a href="../text01/page04.html#log">双曲線正接(tanh)</a>に通して y_h に出力する
</p>


<img src="./img/page03-fig6.png" alt="">
</div>

<br>
<h3>
4. 出力層
</h3>

<p>
最後に出力層を考えます。
</p>

<p>
<a href="./img/page02-fig3.png">前ページの図3</a>から(隠れ層と)出力層を切り出したのが以下の図4です。
</p>

<div class="info">
<input type="checkbox"><b>図7: 出力層のグラフ:</b>

<p>
※ <a href="../text01/page03.html">データフロー・グラフ</a>ではなくて一般的なグラフ表現です
</p>

<img src="./img/page03-fig7.png" alt="">

<p>
$w_{ij}^{\textrm o}$ ・・・ 隠れ層のパーセプトロン No.$i$ の出力信号から、出力層のパーセプトロン No.$j$ への入力に掛けられる重み
</p>
<p>
$b_{j}^{\textrm o}$  ・・・ 出力層のパーセプトロン No.$j$ のバイアス
</p>

</div>

<p>
出力層は M 個のパーセプトロンで出来ていて、それぞれのパーセプトロンは隠れ層からの出力信号を受取ります。
<br>
その際に重みが入力に掛けられ、更にバイアスが足されます。
<br>
そして最後に活性化関数 $f()$ に通して出力されます。
</p>

<p>
つまりパーセプトロンの数と活性化関数が異なるだけで、出力層も隠れ層と同じ様な構造となります。
</p>

<p>
そこで出力層の重みとバイアス全体の行列ををそれぞれ w_o と b_o という名前にすると、これらも<a href="../text01/page04.html#var">変数テンソル</a> として定義します(図8)。
</p>

<div class="info">
<input type="checkbox"><b>図8: 出力層の隠れ層の重みとバイアス</b>

<p>
w_o : 出力層の重み、 K x M 行列 (<a href="../text01/page04.html#var">変数テンソル</a>)
</p>

<p>
b_o : 出力層のバイアス、1 x M 行列 (<a href="../text01/page04.html#var">変数テンソル</a>)
</p>

<p>
※ w_o と b_o の各要素は乱数で初期化する
</p>

<img src="./img/page03-fig8.png" alt="">
</div>

<p>
すると出力層のデータフロー・グラフは図 9 となります。
<br>
なお<a href="./page04.html">次のページ</a>で詳しく説明しますが、今回は「多クラス分類問題」を扱う予定なので活性化関数 $f()$ として <a href="../text01/page04.html#softmax">softmax 関数</a>を使っています。
</p>

<div class="info">
<input type="checkbox"><b>図9: 出力層のデータフロー・グラフ</b>

<p>
隠れ層からの出力信号 y_h と w_o の<a href="../text01/page04.html#matmul">行列積</a> y_h・w_oを求め、それに b_o を<a href="../text01/page04.html#add">足し</a>、<a href="../text01/page04.html#softmax">softmax 関数</a>に通し、y_o に代入する
</p>

<img src="./img/page03-fig9.png" alt="">
</div>

<br>
<h3>
5. 全体のデータフロー・グラフ
</h3>

<p>
以上の各層のデータフロー・グラフを組み合わせると、3層ニューラルネットワーク全体では次のようなデータフロー・グラフとなります。
<br>
後はこのデータフローを元に TensorFlow で 3層ニューラルネットワークを構築するだけです。
</p>

<div class="info">
<input type="checkbox"><b>図10: 3層ニューラルネットワーク全体のデータフロー・グラフ</b>

<p>　</p>
<ul>
<li>入力信号 data をネットワークに入力すると y_o が出力される</li>
<li>赤枠は変数を意味する</li>
</ul>

<img src="./img/page03-fig10.png" alt="">
</div>


<br>
<script>PreNext(3,5)</script>
</body>
</html>
