<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1.0">
<link rel="stylesheet" href="../../../common.css">
<script src="../../../common.js"></script>
<title>4. 基本的なオペレーション</title>
</head>
<body>

<nav class="brcr">
<ol>
<li><a href="../">アクティビティ: TensorFlow によるディープラーニング</a></li>
<li>学習項目: [1] TensorFlow の基本</li>
<li><script>GetTitle()</script></li>
</ol>
</nav>

<h2><script>GetTitle()</script></h2>

<p>
ここでは今回のアクティビティで使用する基本的なオペレーション(以下 OP)について学びます。
</p>

<br>
<h3 id="const">
1. 定数(Constant) OP 
</h3>

<p>
定数 OP はセットした定数テンソルをエッジに出力するだけの OP です。
</p>

<div class="info">
<input type="checkbox"><b>定数 OP : </b>

<p>
書式:  OP名 = tf.constant( x )
</p>

<p>
入力テンソル: x ・・・ 定数値 (スカラー、文字列、ベクトル、行列)
</p>

<p>
出力テンソル : x で指定した定数値
</p>
</div>

<p>
具体的なコード例は次の通りです。
</p>

<div class="info">
<input type="checkbox"><b>コード1: 定数 OP のコード例:</b>

<pre class="wrap">
#coding: UTF-8
import tensorflow as tf
sess = tf.Session()

#スカラー
op_const = tf.constant( 1, tf.float32 )
# tf.float32 は要素を 32 bit浮動小数として扱うという意味

result = sess.run( op_const )
print( result )
# 表示結果
# 1.0

# 3 次元ベクトル
op_const = tf.constant( [1, 2, 3], tf.float32 )
# tf.float32 は各要素を 32 bit浮動小数として扱うという意味

result = sess.run( op_const )
print( result )
# 表示結果
# [1. 2. 3.]

# 3 x 2 行列
op_const = tf.constant([[1, 2], [3, 4], [5, 6]], tf.float32 )
# tf.float32 は各要素を 32 bit浮動小数として扱うという意味

result = sess.run( op_const )
print( result )
# 表示結果
# [[1. 2.]
#  [3. 4.]
#  [5. 6.]]

# 3 x 1 行列 ※ 3 次元ベクトルとの違いに注意！
op_const = tf.constant( [[1], [2], [3]], tf.float32 )
# tf.float32 は各要素を 32 bit浮動小数として扱うという意味

result = sess.run( op_const )
print( result )
# 表示結果
#[[1.]
# [2.]
# [3.]]
</pre>
</div>

<p>
データフロー・グラフは前のページで示した<a href="./img/page03-fig3.png">ハローワールドのグラフ</a>とほとんど同じなので省略します。
</p>

<br>
<h3 id="var">
2. 変数(Variable) OP
</h3>

<p>
変数 OP は<a href="#const">定数 OP</a> と同様にセットしたテンソルをエッジに出力するだけの OP です。
</p>

<p>
定数 OP の場合はセッションの途中で最初にセットした値を変更できませんが、変数 OP は最初にセットした値(つまり初期値)を途中で変更する事ができます。
<br>
ただし
</p>

<p>
<b>
「変数 OP は最初の run を実行する前に初期化しておかないとエラーが出ます」。
</b>
</p>

<p>
なお値の変更方法についてはこのページの最後にある「<a href="#assign">代入 OP </a>」の説明を参照して下さい。
</p>

<div class="info">
<input type="checkbox"><b>変数 OP : </b>

<p>
書式:  OP名 = tf.Variable( x )
</p>

<p>
入力テンソル: x ・・・ 初期値
</p>
<p>
出力テンソル: 現在値
</p>
</div>

<p>
では具体的なコード例を示します。
<br>
コード内で初期値のセット例と初期化方法についても説明しています。
</p>

<div class="info">
<input type="checkbox"><b>コード2: 変数 OP のコード例:</b>

<pre class="wrap">
#coding: UTF-8
import tensorflow as tf
sess = tf.Session()

# 初期値を定数(スカラー)とする例
op_var = tf.Variable( 1 )

# run する前にグラフ内の変数全てを初期化する
sess.run( tf.initialize_all_variables() )
# <font color="red">(注) TFV1 以降は sess.run( tf.global_variables_initializer() )</font>

result = sess.run( op_var )
print( result )
#表示結果
# 1

# 3 x 2 行列を作って要素全てを 0 で初期化する例
op_var = tf.Variable( tf.zeros([3,2]) )

# run する前にグラフ内の変数全てを初期化する
sess.run( tf.initialize_all_variables() )
# <font color="red">(注) TFV1 以降は sess.run( tf.global_variables_initializer() )</font>

result = sess.run( op_var )
print( result )
# 表示結果
# [[ 0.  0.]
#  [ 0.  0.]
#  [ 0.  0.]]

# 3 x 2 行列を作って、要素全てを平均 0、標準偏差 0.1 の正規乱数で初期化する例
op_var = tf.Variable( tf.random_normal( [3, 2], mean=0.0, stddev=0.1 ) )

# run する前にグラフ内の変数全てを初期化する
sess.run( tf.initialize_all_variables() )
# <font color="red">(注) TFV1 以降は sess.run( tf.global_variables_initializer() )</font>

result = sess.run( op_var )
print( result )
# 表示結果(乱数なので毎回変わる)
#[[ 0.08048159  0.03259621]
# [ 0.09933039  0.17510985]
# [-0.0177522  -0.01852487]]
</pre>
</div>

<p>
このデータフローグラフも前のページで示した<a href="./img/page03-fig3.png">ハローワールドのグラフ</a>とほとんど同じなので省略します。
</p>

<br>
<h3 id="add">
3. 足し算(Add) OP 
</h3>

<p>
足し算 OP は 2 つのテンソルの足し算を行う OP です。
</p>

<div class="info">
<input type="checkbox"><b>足し算 OP : </b>

<p>
書式:  OP名 = tf.add( x, y )
</p>

<p>
※ OP名 = x + y と書いてもOK
</p>

<p>
入力テンソル: x と y
</p>
<p>
出力テンソル: x + y
</p>

</div>

<p>
具体的なコード例とデータフローグラフは次の通りです。
<br>
入力テンソル x、y はスカラーでもベクトルでも行列でも構いませんが、テンソルの種類や行数、列数が違うとエラーになります。
</p>

<div class="info">
<input type="checkbox"><b>コード3-1: 足し算 OP のコード例 (スカラーの場合):</b>

<pre class="wrap">
#coding: UTF-8
import tensorflow as tf
sess = tf.Session()

op_const_x = tf.constant( 1 )
op_const_y = tf.constant( 2 )

op_add = tf.add( op_const_x, op_const_y )
# op_add = op_const_x + op_const_y でも可

result = sess.run( op_add )
print( result )
# 表示結果
# 3
</pre>

<br>
<p>
データフロー・グラフ
</p>

<img src="./img/page04-fig3.png" alt="">
</div>

<p>
上の例ではスカラー同士を足していましたが、ベクトルや行列の和の場合は要素毎に値が足し合わされます。
</p>

<div class="info">
<input type="checkbox"><b>コード3-2: 足し算 OP のコード例 (ベクトルの場合):</b>

<pre class="wrap">
#coding: UTF-8
import tensorflow as tf
sess = tf.Session()

op_const_x = tf.constant( [1, 2] )
op_const_y = tf.constant( [3, 4] )

op_add = tf.add( op_const_x, op_const_y )
# op_add = op_const_x + op_const_y でも可

result = sess.run( op_add )
print( result )
# 表示結果
# [4 6]
</pre>

<p>
データフロー・グラフは同じなので略
</p>
</div>

<br>
<h3 id="mul">
4. 掛け算(Mul) OP 
</h3>

<p>
掛け算 OP は 2 つのテンソルの掛け算を行う OP です。
</p>

<p>
なお<b>行列積ではありません</b>のでテンソルが行列の場合は要素毎に値が掛け合わされます。
<br>
行列積は次に説明する<a href="#matmul">tf.matmul</a>を使います。
</p>

<div class="info">
<input type="checkbox"><b>掛け算 OP : </b>

<p>
書式:  OP名 = tf.mul( x, y )
</p>

<p>
<font color="red">※1 Tensorflow V1 以降では mul 関数は無くなりました。代わりに multiply 関数を使います。</font>
<br>
※2 OP名 = x * y と書いてもOK
</p>

<p>
入力テンソル: x と y
</p>
<p>
出力テンソル: x * y
</p>
</div>

<p>
具体的なコード例は次の通りです。
<br>
入力テンソル x、y はスカラーでもベクトルでも行列でも構いませんが、テンソルの種類が違うとエラーになります。
</p>

<div class="info">
<input type="checkbox"><b>コード4-1: 掛け算 OP のコード例(スカラーの場合):</b>

<pre class="wrap">
#coding: UTF-8
import tensorflow as tf
sess = tf.Session()

op_const_x = tf.constant( 2 )
op_const_y = tf.constant( 3 )

op_mul = tf.mul( op_const_x, op_const_y )
# <font color="red">(注) TFV1 以降は op_mul = tf.multiply( op_const_x, op_const_y )</font>
# op_mul = op_const_x * op_const_y でも可

result = sess.run( op_mul )
print( result )
# 表示結果
# 6
</pre>

<br>
<p>
データフロー・グラフ
</p>

<img src="./img/page04-fig4.png" alt="">
</div>

<p>
上の例ではスカラー同士を掛けていましたが、ベクトルや行列の積の場合は要素毎に値が掛け合わされます。
</p>

<div class="info">
<input type="checkbox"><b>コード4-2: 掛け算 OP のコード例 (ベクトルの場合):</b>

<pre class="wrap">
#coding: UTF-8
import tensorflow as tf
sess = tf.Session()

op_const_x = tf.constant( [1, 2] )
op_const_y = tf.constant( [3, 4] )

op_mul = tf.mul( op_const_x, op_const_y )
# <font color="red">(注) TFV1 以降は op_mul = tf.multiply( op_const_x, op_const_y )</font>
# op_mul = op_const_x * op_const_y でも可

result = sess.run( op_mul )
print( result )
# 表示結果
# [3 8]
</pre>

<p>
データフロー・グラフは同じなので略
</p>
</div>

<br>
<h3 id="matmul">
5. 行列積(MatMul) OP 
</h3>

<p>
行列積 OP は 2 つの行列の行列積を行う OP です。
</p>

<div class="info">
<input type="checkbox"><b>行列積 OP : </b>

<p>
書式:  OP名 = tf.matmul( x, y )
</p>

<p>
入力テンソル: x と y (どちらも行列、x の列数と y の行数が異なるとエラー)
</p>
<p>
出力テンソル: x・y
</p>
</div>

<p>
具体的なコード例は次の通りです。
</p>

<div class="info">
<input type="checkbox"><b>コード5: 行列積 OP のコード例:</b>

<pre class="wrap">
#coding: UTF-8
import tensorflow as tf
sess = tf.Session()

op_const_x = tf.constant( [[1,2], [3,4], [5,6]] )
op_const_y = tf.constant( [[1],[2]] )

op_matmul = tf.matmul( op_const_x, op_const_y )

result = sess.run( op_matmul )
print( result )
# 表示結果
#[[ 5]
#  [11]
#  [17]]
</pre>

<br>
<p>
データフロー・グラフ
</p>

<img src="./img/page04-fig5.png" alt="">
</div>

<br>
<h3 id="log">
6. log、 exp、sin、cos、sigmoid などの関数 OP 
</h3>

<p>
log、exp、sin、cos、<a href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid</a> などの関数 OP はそのまま名前通りの演算を行いますが、ベクトルや行列の場合は各要素毎に演算が行われます。
</p>

<div class="info">
<input type="checkbox"><b>: log、 exp、sin、cos、<a href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid</a> などの関数 OP </b>

<p>
書式:  OP名 = tf.log(x) / tf.exp(x) / tf.sin(x) / tf.cos(x) / tf.sigmoid(x) / その他色々
</p>

<p>
入力テンソル: x
</p>
<p>
出力テンソル: それぞれの演算結果
</p>
</div>

<p>
具体的なコード例は次の通りです。
</p>

<div class="info">
<input type="checkbox"><b>コード6: log、 exp、sin、cos、その他の OP のコード例:</b>

<pre class="wrap">
#coding: UTF-8
import tensorflow as tf
sess = tf.Session()

op_const_x = tf.constant( [ 1, 2, 3], tf.float32 )
# tf.float32 は各要素を 32 bit浮動小数として扱うという意味

# log の例
op_log = tf.log( op_const_x )
result = sess.run( op_log )
print( result )
# 表示結果
# [ 0.          0.69314718  1.09861231]

# sigmoid の例
op_sigmoid = tf.sigmoid( op_const_x )
result = sess.run( op_sigmoid )
print( result )
# 表示結果
# [ 0.7310586 0.88079703 0.95257413]
</pre>

<br>
<p>
データフロー・グラフ
</p>

<img src="./img/page04-fig6.png" alt="">
</div>


<br>
<h3 id="softmax">
7. SoftMax OP 
</h3>

<p>
<a href="https://en.wikipedia.org/wiki/Softmax_function">SoftMax</a> OP はニューラルネットワークの出力層で良く使われている OP です。
<br>
出力されるテンソルの各要素の値は確率の数字を表しています(詳しくはディープラーニングの学習項目で説明します)。
</p>

<div class="info">
<input type="checkbox"><b>: SoftMax OP </b>

<p>
書式:  OP名 = tf.nn.softmax( x )
</p>

<p>
入力テンソル: x (ベクトルまたは行列)
</p>
<p>
出力テンソル: 以下のようにして求めたテンソル B を出力する。
</p>
<ol>
<li>x の各要素毎に exp() を計算して、テンソル A に代入する</li>
<li>A の要素を全て足して変数 a に入れる</li>
<li>A の各要素を a で割ってテンソル B に代入する</li>
</ol>

</div>

<p>
具体的なコード例は次の通りです。
</p>

<div class="info">
<input type="checkbox"><b>コード7: SoftMax OP のコード例:</b>

<pre class="wrap">
#coding: UTF-8
import tensorflow as tf
sess = tf.Session()

op_const_x = tf.constant( [ 1, 2, 3], tf.float32 )
# tf.float32 は各要素を 32 bit浮動小数として扱うという意味

op_softmax = tf.nn.softmax( op_const_x )

result = sess.run( op_softmax )
print( result )
# 表示結果
# [ 0.09003057  0.24472848  0.66524094]
# 結果を全て足すと 1 になる → 各要素は確率の数字を表している
</pre>

<br>
<p>
データフロー・グラフ
</p>

<img src="./img/page04-fig7.png" alt="">
</div>


<br>
<h3 id="redsum">
8. 総和(Reduce_Sum) OP 
</h3>

<p>
総和 OP はテンソルの要素を全て足しあわせて出力する OP です。
</p>

<div class="info">
<input type="checkbox"><b>総和 OP : </b>

<p>
書式:  OP名 = tf.reduce_sum( x )
</p>

<p>
入力テンソル: x  (ベクトルまたは行列)
</p>
<p>
出力テンソル: 要素の総和
</p>
</div>

<p>
具体的なコード例は次の通りです。
</p>

<div class="info">
<input type="checkbox"><b>コード8: 総和 OP のコード例:</b>

<pre class="wrap">
#coding: UTF-8
import tensorflow as tf
sess = tf.Session()

op_const = tf.constant( [ 1, 2, 3] )

op_rs = tf.reduce_sum( op_const )

result = sess.run( op_rs )
print( result )
# 表示結果
# 6
</pre>

<br>
<p>
データフロー・グラフ
</p>

<img src="./img/page04-fig8.png" alt="">
</div>

<br>
<h3 id="assign">
9. 代入(Assign) OP 
</h3>

<p>
代入(Assign) OP は<a href="#var">変数 OP</a> に保存されている値を変更する OP です。
<br>
今回のアクティビティでは使いませんが一応説明しておきます。
</p>

<div class="info">
<input type="checkbox"><b>代入(Assign) OP : </b>

<p>
書式:  OP名 = tf.assign( x, y )
</p>

<p>
入力テンソル: 
<br>
x ・・・ 出力値を変更したい<a href="#var">変数 OP</a> (※)
<br>
y ・・・ 新しい値
</p>
<p>
出力テンソル: y がそのまま出力される
</p>

<p>
※ x の値が変更されるタイミングは run が完了した時です
</p>

</div>

<p>
具体的なコード例とデータフロー・グラフは次の通りです。
<br>
初期化すると変数の値が元に戻っていることに注目して下さい。
</p>

<div class="info">
<input type="checkbox"><b>コード9: 代入 OP のコード例:</b>

<pre class="wrap">
#coding: UTF-8
import tensorflow as tf
sess = tf.Session()

# 初期値はスカラーの 1
op_var = tf.Variable( 1 )

# run する前にグラフ内の変数全てを初期化する
sess.run(tf.initialize_all_variables())
# <font color="red">(注) TFV1 以降は sess.run( tf.global_variables_initializer() )</font>

result = sess.run( op_var )
print( result )
#表示結果
# 1

# スカラー 2 を代入
op_asn = tf.assign(op_var, 2 )

result = sess.run( op_asn )
print( result )
#表示結果
# 2

result = sess.run( op_var )
print( result )
#表示結果 : 2 に変わっている
# 2

# 再びグラフ内の変数全てを初期化する
sess.run(tf.initialize_all_variables())
# <font color="red">(注) TFV1 以降は sess.run( tf.global_variables_initializer() )</font>

result = sess.run( op_var )
print( result )
#表示結果 : 初期値 1 に戻る
# 1
</pre>

<br>
<p>
データフロー・グラフ
</p>

<img src="./img/page04-fig9.png" alt="">
</div>

<br>
<script>PreNext(4,5)</script>
</body>
</html>
