<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1.0">
<link rel="stylesheet" href="../../../common.css">
<script src="../../../common.js"></script>
<title>4. 基本的なオペレーション</title>
</head>
<body>

<nav class="brcr">
<ol>
<li><a href="../">アクティビティ: TensorFlow によるディープラーニング</a></li>
<li>学習項目: [1] TensorFlow の基本</li>
<li><script>GetTitle()</script></li>
</ol>
</nav>

<h2><script>GetTitle()</script></h2>

<p>
ここでは今回のアクティビティで使用する基本的なオペレーションについて学びます。
</p>

<br>
<h3 id="const">
1. 定数オペレーション: tf.constant
</h3>

<p>
定数オペレーションは与えられた初期値を元にして定数テンソルを出力するオペレーションです。
<br>
定数テンソルなので、演算途中に値を変更することは出来ません。
</p>

<div class="info">
<input type="checkbox"><b>定数オペレーション: </b>

<p>
書式:  tf.constant( x, dtype=t )
</p>

<p>
引数:
<br>
　x ・・・ 初期値。形式はスカラー、ベクトル、行列、文字列など。np.array などの非テンソルでも指定可
<br>
　t・・・整数や浮動小数点数などテンソル形式を指定する
</p>

<p>
出力 : x を元に作成した定数テンソル
</p>
</div>

<p>
具体的なコード例とデータフローグラフは次の通りです。 
</p>

<div class="info">
<input type="checkbox"><b>コード1: 定数オペレーションのコード例とデータフローグラフ</b>

<pre class="wrap">
import tensorflow as tf

#スカラー
# dtype=tf.float32 は要素を 32 bit浮動小数点数として扱うという意味

A = tf.constant( 1, dtype=tf.float32 )
print( A.numpy() )

# 表示結果
# 1.0

# 3 次元ベクトル
# dtype=tf.float32 は各要素を 32 bit浮動小数点数として扱うという意味

A = tf.constant( [1, 2, 3], dtype=tf.float32 )
print( A.numpy() )

# 表示結果
# [1. 2. 3.]

# 3 x 2 行列
# dtype=tf.float32 は各要素を 32 bit浮動小数点数として扱うという意味

A = tf.constant([[1, 2], [3, 4], [5, 6]], dtype=tf.float32 )
print( A.numpy() )

# 表示結果
# [[1. 2.]
#  [3. 4.]
#  [5. 6.]]

# 3 x 1 行列 
# dtype=tf.float32 は各要素を 32 bit浮動小数点数として扱うという意味

A = tf.constant( [[1], [2], [3]], dtype=tf.float32 )
print( A.numpy() )

# 表示結果 ※ 3 次元ベクトルとの違いに注意！
#[[1.]
# [2.]
# [3.]]
</pre>

<img src="./img/page04-fig1.png" alt="">
</div>

</div>

<br>
<h3 id="var">
2. 変数オペレーション: tf.Variable
</h3>

<p>
変数オペレーションは<a href="#const">定数オペレーション</a>と同様に、与えられた初期値を元にして変数テンソルを出力するオペレーションです。 
<br>
ただし定数テンソルと異なり、変数テンソルは assign メソッドを使って値を演算途中で変更する事ができます。
</p>

<div class="info">
<input type="checkbox"><b>変数オペレーション: </b>

<p>
書式:  tf.Variable( x, dtype=t )
</p>

<p>
引数:
<br>
　x ・・・ 初期値。形式はスカラー、ベクトル、行列、文字列など。np.array などの非テンソルでも指定可 
<br>
　t・・・整数や浮動小数点数などテンソル形式を指定する
</p>
<p>
出力: x を元に作成した変数テンソル 
</p>

<p>
値の変更方法:  テンソル名.assign( 新しい値 )
</p>

</div>

<p>
具体的なコード例とデータフローグラフは次の通りです。 
<br>
ついでなので値の変更方法も例に含めています。
</p>

<div class="info">
<input type="checkbox"><b>コード2: 変数オペレーションのコード例とデータフローグラフ</b>

<pre class="wrap">
import tensorflow as tf

# スカラー
# dtype=tf.float32 は要素を 32 bit浮動小数点数として扱うという意味

A = tf.Variable( 1, dtype=tf.float32 )
print( A.numpy() )

#表示結果
# 1.0

# 3 x 2 行列
# dtype=tf.float32 は各要素を 32 bit浮動小数点数として扱うという意味

A = tf.Variable([[1, 2], [3, 4], [5, 6]], dtype=tf.float32 )
print( A.numpy() )

# 表示結果
# [[1. 2.]
#  [3. 4.]
#  [5. 6.]]

# assign メソッドで値を変更
A.assign( [[-1,-2],[-3,-4],[-5,-6]] )
print( A.numpy() )

# 表示結果
# [[-1. -2.]
#  [-3. -4.]
# [-5. -6.]]

# 3 x 2 行列を作って要素全てを 0 で初期化
# dtype=tf.float32 は各要素を 32 bit浮動小数点数として扱うという意味

A = tf.Variable( tf.zeros([3,2]), dtype=tf.float32 )
print( A.numpy() )

# 表示結果
# [[ 0.  0.]
#  [ 0.  0.]
#  [ 0.  0.]]

# 3 x 2 行列を作って、要素全てを平均 0、標準偏差 0.1 の正規乱数で初期化
A = tf.Variable( tf.random.normal( [3, 2], mean=0.0, stddev=0.1 ) )
print( A.numpy() )

# 表示結果 ※ 乱数なので毎回変わる
# [[-0.0252009071 -0.0138573265]
#  [-0.0525492802 -0.00620838907]
#  [0.00722313905 -0.0197176021]]

<img src="./img/page04-fig2.png" alt="">
</pre>
</div>

<br>
<h3 id="add">
3. 足し算オペレーション: tf.math.add
</h3>

<p>
足し算オペレーションは 2 つのテンソルの足し算を行うオペレーションです。
</p>

<div class="info">
<input type="checkbox"><b>足し算オペレーション: </b>

<p>
書式:  tf.math.add( x, y )
</p>

<p>
※ x + y や tf.add(x,y) と書いても良い
</p>

<p>
引数: 
<br>
　x、y ・・・テンソル。定数テンソルでも変数テンソルでもどちらでも可
</p>

<p>
出力: x + y の結果を代入した定数テンソル
</p>

<p>
※1 ベクトルや行列の足し算の場合は要素毎に足し合わされます
</p>

<p>
※2 テンソル x、y のタイプや形状が違うとエラーになります。(例) xがスカラーでyが行列、xとyの行数や列数が異なる、etc.
</p>

</div>

<p>
具体的なコード例とデータフローグラフは次の通りです。
</p>

<div class="info">
<input type="checkbox"><b>コード3: 足し算オペレーションのコード例とデータフローグラフ</b>

<pre class="wrap">
import tensorflow as tf

# スカラー同士
A = tf.constant( 1, dtype=tf.float32 )
B = tf.constant( 2, dtype=tf.float32 )
C = tf.math.add( A, B )
print( C.numpy() )

# 表示結果
# 3.0

# 行列同士
A = tf.constant( [[1,2],[3,4]], dtype=tf.float32 )
B = tf.constant( [[5,6],[7,8]], dtype=tf.float32 )
C = tf.math.add( A, B )
print( C.numpy() )

# 表示結果 ※ ベクトルや行列の足し算の場合は要素毎に足し合わされる
#[[ 6.  8.]
# [10. 12.]]
</pre>

<p>
データフロー・グラフ
</p>

<img src="./img/page04-fig3.png" alt="">
</div>

<br>
<h3 id="mul">
4. 掛け算オペレーション: tf.math.multiply
</h3>

<p>
掛け算オペレーションは 2 つのテンソルの掛け算を行うオペレーションです。
</p>

<p>
なお<b>行列積ではありません</b>のでテンソルが行列の場合は要素毎に値が掛け合わされます。
<br>
行列積は次に説明する<a href="#matmul">matmul</a>を使います。
</p>

<div class="info">
<input type="checkbox"><b>掛け算オペレーション: </b>

<p>
書式:  tf.math.multiply( x, y )
</p>

<p>
※ x * y や tf.multiply(x,y) と書いても良い
</p>

<p>
引数: 
<br>
　x、y ・・・テンソル。定数テンソルでも変数テンソルでもどちらでも可
</p>
<p>
出力: x * y の結果を代入した定数テンソル
</p>

<p>
※1 ベクトルや行列の掛け算の場合は要素毎に掛け合わされます
</p>
<p>
※2 テンソル x、y のタイプや形状が違うとエラーになります。(例) xがスカラーでyが行列、xとyの行数や列数が異なる、etc.
</p>

</div>

<p>
具体的なコード例とデータフローグラフは次の通りです。
</p>

<div class="info">
<input type="checkbox"><b>コード4: 掛け算オペレーションのコード例とデータフローグラフ</b>

<pre class="wrap">
import tensorflow as tf

# スカラー同士
A = tf.constant( 1, dtype=tf.float32 )
B = tf.constant( 2, dtype=tf.float32 )
C = tf.math.multiply( A, B )
print( C.numpy() )

# 表示結果
# 2.0

# 行列同士
A = tf.constant( [[1,2],[3,4]], dtype=tf.float32 )
B = tf.constant( [[5,6],[7,8]], dtype=tf.float32 )
C = tf.math.multiply( A, B )
print( C.numpy() )

# 表示結果 ※ ベクトルや行列の足し算の場合は要素毎に掛け合わされる
#[[ 5. 12.]
# [21. 32.]]
</pre>

<br>
<p>
データフロー・グラフ
</p>

<img src="./img/page04-fig4.png" alt="">
</div>

<br>
<h3 id="matmul">
5. 行列積オペレーション : tf.linalg.matmul
</h3>

<p>
行列積オペレーションは 2 つの行列の行列積を行うオペレーションです。
</p>

<div class="info">
<input type="checkbox"><b>行列積オペレーション: </b>

<p>
書式:  tf.linalg.matmul( x, y )
</p>

<p>
 引数:
<br>
　x、y ・・・行列型のテンソル。定数テンソルでも変数テンソルでもどちらでも可 
</p>
<p>
出力: 行列積 x・y の結果を代入した定数テンソル
</p>

<p>
※1 x の列数と y の行数が異なると行列積が出来ないのでエラーになります
</p>
<p>
※2 tf.linalg.matmul( x, y ) と tf.linalg.matmul( y, x ) の結果は一般的に異なります
</p>

</div>

<p>
具体的なコード例とデータフローグラフは次の通りです。

</p>

<div class="info">
<input type="checkbox"><b>コード5: 行列積オペレーションのコード例とデータフローグラフ</b>

<pre class="wrap">
import tensorflow as tf

A = tf.constant( [[1,2], [3,4], [5,6]], dtype=tf.float32 )
B = tf.constant( [[1],[2]], dtype=tf.float32 )
C = tf.linalg.matmul( A, B )
print( C.numpy() )

# 表示結果
#[[ 5.]
#  [11.]
#  [17.]]
</pre>

<br>
<p>
データフロー・グラフ
</p>

<img src="./img/page04-fig5.png" alt="">
</div>

<br>
<h3 id="log">
6. f(x) で表される演算系オペレーション
</h3>

<p>
log、exp、sin、cos、<a href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid</a> などの f(x) で表される演算系オペレーションはそのまま名前通りの演算を行います。
</p>

<div class="info">
<input type="checkbox"><b> f(x) で表される演算系オペレーション:</b>

<p>
書式: f(x)
</p>

<p>
 引数:
<br>
　x ・・・テンソル。定数テンソルでも変数テンソルでもどちらでも可 
</p>
<p>
出力: 演算結果を代入した定数テンソル 
</p>

<p>
※ ベクトルや行列が入力された場合 f(x) によって出力されるテンソルの形式が変わります。log(x)やsigmoid(x)などは要素毎に演算されます
</p>

</div>

<p>
具体的なコード例はデータフローグラフは次の通りです。
<br>
今回は自然対数と<a href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid(x)</a>を例として挙げています。
</p>

<div class="info">
<input type="checkbox"><b>コード6: 演算系オペレーションのコード例とデータフローグラフ</b>

<pre class="wrap">
import tensorflow as tf

A = tf.constant( [ 1, 2, 3], tf.float32 )

# log(x) の例 ※自然対数
B = tf.math.log( A )
print( B.numpy() )

# 表示結果  ※ベクトルや行列の場合は要素毎に演算される
# [ 0. 0.69314718  1.09861231]

# sigmoid(x) の例
B = tf.math.sigmoid( A )
print( B.numpy() )

# 表示結果 ※ベクトルや行列の場合は要素毎に演算される
# [ 0.7310586 0.88079703 0.95257413]
</pre>

<br>
<p>
データフロー・グラフ
</p>

<img src="./img/page04-fig6.png" alt="">
</div>


<br>
<h3 id="softmax">
7. softmaxオペレーション: tf.nn.softmax
</h3>

<p>
<a href="https://en.wikipedia.org/wiki/Softmax_function">softmax</a>オペレーションも上で挙げた<a href="#log">f(x)</a>で表される演算系オペレーションのひとつなのですが、ニューラルネットワークの<a href="https://ja.wikipedia.org/wiki/One-hot">one-hotベクトル</a>型の出力層で良く使われている演算なので、項目を分けて説明します。
</p>

<div class="info">
<input type="checkbox"><b>: softmaxオペレーション</b>

<p>
書式: tf.nn.softmax( x )
</p>

<p>
引数:
<br>
　x ・・・テンソル。定数テンソルでも変数テンソルでもどちらでも可 
</p>

<p>
出力: 以下のようにして求めた定数テンソル
</p>
<ol>
<li>x の各要素毎に exp() を計算して、テンソル A に代入する</li>
<li>A の要素を全て足して変数 a に入れる</li>
<li>A の各要素を a で割って出力テンソルとする</li>
</ol>

<p>
※ 出力されたテンソルの各要素の値は確率を表しています
</p>


</div>

<p>
具体的なコード例とデータフローグラフは次の通りです。 
</p>

<div class="info">
<input type="checkbox"><b>コード7: softmaxオペレーションのコード例とデータフローグラフ</b>

<pre class="wrap">
import tensorflow as tf

A = tf.constant( [ 1, 2, 3], tf.float32 )
B = tf.nn.softmax( A )
print( B.numpy() )

# 表示結果 ※ 結果を全て足すと 1 になる → 各要素は確率の数字を表している
# [ 0.09003057  0.24472848  0.66524094]
</pre>

<br>
<p>
データフロー・グラフ
</p>

<img src="./img/page04-fig7.png" alt="">
</div>


<br>
<h3 id="redsum">
8. 総和オペレーション: tf.math.reduce_sum
</h3>

<p>
総和オペレーションはテンソルの要素を全て足し合わせて出力するオペレーションです。
</p>

<p>
このオペレーションも上で挙げた<a href="#log">f(x)</a>で表される演算系オペレーションのひとつなのですが、ニューラルネットワークで良く使われている演算なので項目を分けて説明します。
</p>

<div class="info">
<input type="checkbox"><b>総和オペレーション: </b>

<p>
書式:  tf.math.reduce_sum( x )
</p>

<p>
引数:
<br>
　x ・・・テンソル。定数テンソルでも変数テンソルでもどちらでも可 
</p>
<p>
出力: 要素をすべて足し合わせた定数テンソル
</p>
</div>

<p>
具体的なコード例とデータフローグラフは次の通りです。 
</p>

<div class="info">
<input type="checkbox"><b>コード8: 総和オペレーションのコード例とデータフローグラフ</b>

<pre class="wrap">
import tensorflow as tf
A = tf.constant( [ 1, 2, 3], tf.float32 )
B = tf.math.reduce_sum( A )
print( B.numpy() )

# 表示結果
# 6.0
</pre>

<br>
<p>
データフロー・グラフ
</p>

<img src="./img/page04-fig8.png" alt="">
</div>

<br>
<script>PreNext(4,5)</script>
</body>
</html>
