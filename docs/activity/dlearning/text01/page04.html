<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1.0">
<link rel="stylesheet" href="../../../common.css">
<script src="../../../common.js"></script>
<title>4. 基本的な OP ノード</title>
</head>
<body>

<nav class="brcr">
<ol>
<li><a href="../">アクティビティ: TensorFlow によるディープラーニング</a></li>
<li>学習項目: [1] TensorFlow の基本</li>
<li><script>GetTitle()</script></li>
</ol>
</nav>

<h2><script>GetTitle()</script></h2>

<p>
ここでは今回のアクティビティで使用する基本的な OP ノードについて学びます。
</p>

<br>
<h3 id="const">
1. 定数(Constant) OP ノード
</h3>

<p>
定数 OP ノードはセットした定数テンソルをエッジに出力する OP ノードです。
</p>

<div class="info">
<input type="checkbox"><b>定数 OP ノード: </b>

<p>
書式:  ノード名 = tf.constant(定数値)
</p>

<p>
入力テンソル: 無し
<br>
出力テンソル: カッコ内で指定した定数値
</p>
</div>

<p>
具体的なコード例は次の通りです。
</p>

<div class="info">
<input type="checkbox"><b>コード1: 定数 OP ノードのコード例:</b>

<pre class="wrap">
#coding: UTF-8
import tensorflow as tf
sess = tf.Session()

#スカラー
op_const = tf.constant( 1, tf.float32 )
# tf.float32 は要素を 32 bit浮動小数として扱うという意味

result = sess.run( op_const )
print( result )
# 表示結果
# 1.0

# 3 次元ベクトル
op_const = tf.constant( [1, 2, 3], tf.float32 )
# tf.float32 は各要素を 32 bit浮動小数として扱うという意味

result = sess.run( op_const )
print( result )
# 表示結果
# [1. 2. 3.]

# 3 x 1 行列
op_const = tf.constant( [[1], [2], [3]], tf.float32 )
# tf.float32 は各要素を 32 bit浮動小数として扱うという意味

result = sess.run( op_const )
print( result )
# 表示結果
#[[1.]
# [2.]
# [3.]]

# 3 x 2 行列
op_const = tf.constant([[1, 2], [3, 4], [5, 6]], tf.float32 )
# tf.float32 は各要素を 32 bit浮動小数として扱うという意味

result = sess.run( op_const )
print( result )
# 表示結果
# [[1. 2.]
#  [3. 4.]
#  [5. 6.]]
</pre>
</div>

<p>
データフローグラフは前のページで示した<a href="./img/page03-fig3.png">ハローワールドのグラフ</a>とほとんど同じなので省略します。
</p>

<br>
<h3 id="var">
2. 変数(Variable) OP ノード
</h3>

<p>
変数 OP ノードは定数 OP ノードと同様にセットしたテンソルをエッジに出力する OP ノードです。
</p>

<p>
定数 OP ノードの場合はセッションの途中で最初にセットした値を変更できませんが、変数 OP ノードは最初にセットした値(つまり初期値)を途中で変更する事ができます。ただし
</p>

<p>
<b>
「変数 OP ノードは最初の run を実行する前に初期化しておかないとエラーが出ます」。
</b>
</p>

<p>
なお値の変更方法についてはこのページの最後にある「代入 OP ノード」の説明を参照して下さい。
</p>

<div class="info">
<input type="checkbox"><b>変数 OP ノード: </b>

<p>
書式:  ノード名 = tf.Variable( x )
</p>

<p>
入力テンソル: x ・・・ 初期値
<br>
出力テンソル: 現在値
</p>
</div>

<p>
では具体的なコード例を示します。コード内で初期値のセット例と初期化方法についても説明しています。
</p>

<div class="info">
<input type="checkbox"><b>コード2: 変数 OP ノードのコード例:</b>

<pre class="wrap">
#coding: UTF-8
import tensorflow as tf
sess = tf.Session()

# 初期値を定数(スカラー)とする例
op_var = tf.Variable( 1 )

# run する前にグラフ内の変数全てを初期化する
sess.run( tf.initialize_all_variables() )

result = sess.run( op_var )
print( result )
#表示結果
# 1

# 3 x 2 行列を作って要素全てを 0 で初期化する例
op_var = tf.Variable( tf.zeros([3,2]) )

# run する前にグラフ内の変数全てを初期化する
sess.run( tf.initialize_all_variables() )

result = sess.run( op_var )
print( result )
# 表示結果
# [[ 0.  0.]
#  [ 0.  0.]
#  [ 0.  0.]]

# 3 x 2 行列を作って、要素全てを平均 0、標準偏差 0.1 の正規乱数で初期化する例
op_var = tf.Variable( tf.random_normal( [3, 2], mean=0.0, stddev=0.1 ) )

# run する前にグラフ内の変数全てを初期化する
sess.run( tf.initialize_all_variables() )

result = sess.run( op_var )
print( result )
# 表示結果(乱数なので毎回変わる)
#[[ 0.08048159  0.03259621]
# [ 0.09933039  0.17510985]
# [-0.0177522  -0.01852487]]
</pre>
</div>

<p>
このデータフローグラフも前のページで示した<a href="./img/page03-fig3.png">ハローワールドのグラフ</a>とほとんど同じなので省略します。
</p>

<br>
<h3>
3. 足し算(Add) OP ノード
</h3>

<p>
足し算 OP ノードは 2 つのテンソルの足し算を行うノードです。
</p>

<div class="info">
<input type="checkbox"><b>足し算 OP ノード: </b>

<p>
書式:  ノード名 = tf.add( x, y )
</p>

<p>
※ ノード名 = x + y と書いてもOK
</p>

<p>
入力テンソル: x と y
<br>
出力テンソル: x + y
</p>

</div>

<p>
具体的なコード例とデータフローグラフは次の通りです。入力テンソル x、y はスカラーでもベクトルでも行列でも構いませんが、テンソルの種類や行数、列数が違うとエラーになります。
</p>

<div class="info">
<input type="checkbox"><b>コード3-1: 足し算 OP ノードのコード例 (スカラーの場合):</b>

<pre class="wrap">
#coding: UTF-8
import tensorflow as tf
sess = tf.Session()

op_const_x = tf.constant( 1 )
op_const_y = tf.constant( 2 )

op_add = tf.add( op_const_x, op_const_y )
# op_add = op_const_x + op_const_y でも可

result = sess.run( op_add )
print( result )
# 表示結果
# 3
</pre>

<br>
<p>
データフローグラフ
</p>

<img src="./img/page04-fig3.png" alt="">
</div>

<p>
上の例ではスカラー同士を足していましたが、ベクトルや行列の和の場合は要素毎に値が足し合わされます。
</p>

<div class="info">
<input type="checkbox"><b>コード3-2: 足し算 OP ノードのコード例 (ベクトルの場合):</b>

<pre class="wrap">
#coding: UTF-8
import tensorflow as tf
sess = tf.Session()

op_const_x = tf.constant( [1, 2] )
op_const_y = tf.constant( [3, 4] )

op_add = tf.add( op_const_x, op_const_y )
# op_add = op_const_x + op_const_y でも可

result = sess.run( op_add )
print( result )
# 表示結果
# [4 6]
</pre>

<p>
データフローグラフは同じなので略
</p>
</div>

<br>
<h3 id="mul">
4. 掛け算(Mul) OP ノード
</h3>

<p>
掛け算 OP ノードは 2 つのテンソルの掛け算を行うノードです。
</p>

<p>
なお行列積ではありませんのでテンソルが行列の場合は要素毎に値が掛け合わされます。行列積は次の項目で扱います。
</p>

<div class="info">
<input type="checkbox"><b>掛け算 OP ノード: </b>

<p>
書式:  ノード名 = tf.mul( x, y )
</p>

<p>
※ ノード名 = x * y と書いてもOK
</p>

<p>
入力テンソル: x と y
<br>
出力テンソル: x * y
</p>
</div>

<p>
具体的なコード例は次の通りです。入力テンソル x、y はスカラーでもベクトルでも行列でも構いませんが、テンソルの種類が違うとエラーになります。
</p>

<div class="info">
<input type="checkbox"><b>コード4-1: 掛け算 OP ノードのコード例(スカラーの場合):</b>

<pre class="wrap">
#coding: UTF-8
import tensorflow as tf
sess = tf.Session()

op_const_x = tf.constant( 2 )
op_const_y = tf.constant( 3 )

op_mul = tf.mul( op_const_x, op_const_y )
# op_mul = op_const_x * op_const_y でも可

result = sess.run( op_mul )
print( result )
# 表示結果
# 6
</pre>

<br>
<p>
データフローグラフ
</p>

<img src="./img/page04-fig4.png" alt="">
</div>

<p>
上の例ではスカラー同士を掛けていましたが、ベクトルや行列の積の場合は要素毎に値が掛け合わされます。
</p>

<div class="info">
<input type="checkbox"><b>コード4-2: 掛け算 OP ノードのコード例 (ベクトルの場合):</b>

<pre class="wrap">
#coding: UTF-8
import tensorflow as tf
sess = tf.Session()

op_const_x = tf.constant( [1, 2] )
op_const_y = tf.constant( [3, 4] )

op_mul = tf.mul( op_const_x, op_const_y )
# op_mul = op_const_x * op_const_y でも可

result = sess.run( op_mul )
print( result )
# 表示結果
# [3 8]
</pre>

<p>
データフローグラフは同じなので略
</p>
</div>

<br>
<h3>
5. 行列積(MatMul) OP ノード
</h3>

<p>
行列積 OP ノードは 2 つの行列の行列積を行うノードです。
</p>

<div class="info">
<input type="checkbox"><b>行列積 OP ノード: </b>

<p>
書式:  ノード名 = tf.matmul( x, y )
</p>

<p>
入力テンソル: x と y (どちらも行列、x の列数と y の行数が異なるとエラー)
<br>
出力テンソル: x・y
</p>
</div>

<p>
具体的なコード例は次の通りです。
</p>

<div class="info">
<input type="checkbox"><b>コード5: 行列積 OP ノードのコード例:</b>

<pre class="wrap">
#coding: UTF-8
import tensorflow as tf
sess = tf.Session()

op_const_x = tf.constant( [[1,2], [3,4], [5,6]] )
op_const_y = tf.constant( [[1],[2]] )

op_mmul = tf.matmul( op_const_x, op_const_y )

result = sess.run( op_mmul )
print( result )
# 表示結果
#[[ 5]
#  [11]
#  [17]]
</pre>

<br>
<p>
データフローグラフ
</p>

<img src="./img/page04-fig5.png" alt="">
</div>

<br>
<h3 id="log">
6. log、 exp、sin、cos、sigmoid などの関数 OP ノード
</h3>

<p>
log、exp、sin、cos、<a href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid</a> などの関数 OP ノードはそのままその通りの演算を行いますが、ベクトルや行列の場合は各要素毎に演算が行われます。
</p>

<div class="info">
<input type="checkbox"><b>: log、 exp、sin、cos、<a href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid</a> などの関数 OP ノード</b>

<p>
書式:  ノード名 = tf.f( x )
</p>

<p>
f(x) = log(x)、exp(x)、sin(x)、cos(x)、sigmoid(x) その他色々
</p>

<p>
入力テンソル: x
<br>
出力テンソル: f(x)
</p>
</div>

<p>
具体的なコード例は次の通りです。
</p>

<div class="info">
<input type="checkbox"><b>コード6: log、 exp、sin、cos、その他の OP ノードのコード例( log の場合 ):</b>

<pre class="wrap">
#coding: UTF-8
import tensorflow as tf
sess = tf.Session()

op_const_x = tf.constant( [ 1, 2, 3], tf.float32 )
# tf.float32 は各要素を 32 bit浮動小数として扱うという意味

op_log = tf.log( op_const_x )

result = sess.run( op_log )
print( result )
# 表示結果
# [ 0.          0.69314718  1.09861231]
</pre>

<br>
<p>
データフローグラフ
</p>

<img src="./img/page04-fig6.png" alt="">
</div>


<br>
<h3 id="softmax">
7. SoftMax OP ノード
</h3>

<p>
<a href="https://en.wikipedia.org/wiki/Softmax_function">SoftMax</a> OP ノードはニューラルネットワークの出力層で良く使われているノードで、出力されるテンソルの各要素の値は確率の数字を表しています。
<br>
詳しくはディープラーニングの学習項目で説明します。
</p>

<div class="info">
<input type="checkbox"><b>: SoftMax OP ノード</b>

<p>
書式:  ノード名 = tf.nn.softmax( x )
</p>

<p>
入力テンソル: x
<br>
出力テンソル: 以下のようにして求めたテンソル B を出力する。
</p>
<ol>
<li>x の各要素毎に exp() を計算して、テンソル A に代入する</li>
<li>A の要素を全て足して変数 a に入れる</li>
<li>A の各要素を a で割ってテンソル B に代入する</li>
</ol>

</div>

<p>
具体的なコード例は次の通りです。
</p>

<div class="info">
<input type="checkbox"><b>コード7: SoftMax OP ノードのコード例:</b>

<pre class="wrap">
#coding: UTF-8
import tensorflow as tf
sess = tf.Session()

op_const_x = tf.constant( [ 1, 2, 3], tf.float32 )
# tf.float32 は各要素を 32 bit浮動小数として扱うという意味

op_smax = tf.nn.softmax( op_const_x )

result = sess.run( op_smax )
print( result )
# 表示結果
# [ 0.09003057  0.24472848  0.66524094]
# 結果を全て足すと 1 になる → 各要素は確率の数字を表している
</pre>

<br>
<p>
データフローグラフ
</p>

<img src="./img/page04-fig7.png" alt="">
</div>


<br>
<h3 id="redsum">
8. 総和(Reduce_Sum) OP ノード
</h3>

<p>
総和 OP ノードはテンソルの要素を全て足しあわせて出力するノードです。
</p>

<div class="info">
<input type="checkbox"><b>総和 OP ノード: </b>

<p>
書式:  ノード名 = tf.reduce_sum( x )
</p>

<p>
入力テンソル: x
<br>
出力テンソル: 要素の総和
</p>
</div>

<p>
具体的なコード例は次の通りです。
</p>

<div class="info">
<input type="checkbox"><b>コード8: 総和 OP ノードのコード例:</b>

<pre class="wrap">
#coding: UTF-8
import tensorflow as tf
sess = tf.Session()

op_const = tf.constant( [ 1, 2, 3] )

op_rs = tf.reduce_sum( op_const )

result = sess.run( op_rs )
print( result )
# 表示結果
# 6
</pre>

<br>
<p>
データフローグラフ
</p>

<img src="./img/page04-fig8.png" alt="">
</div>

<br>
<h3>
9. 代入(Assign) OP ノード
</h3>

<p>
代入(Assign) OP ノードは変数 OP ノードに保存されている値を変更するノードです。
今回のアクティビティでは使いませんが一応説明しておきます。
</p>

<div class="info">
<input type="checkbox"><b>代入(Assign) OP ノード: </b>

<p>
書式:  ノード名 = tf.assign( x )
</p>

<p>
※ 変数の値が変更されるタイミングは run が完了した時
</p>

<p>
入力テンソル: x ・・・ 新しい値
<br>
出力テンソル: x がそのまま出力される
</p>

</div>

<p>
具体的なコード例とデータフローグラフは次の通りです。sess.run(tf.initialize_all_variables()) で初期化すると変数の値が元に戻っていることに注目して下さい。
</p>

<div class="info">
<input type="checkbox"><b>コード9: 代入 OP ノードのコード例:</b>

<pre class="wrap">
#coding: UTF-8
import tensorflow as tf
sess = tf.Session()

# 初期値はスカラーの 1
op_var = tf.Variable( 1 )

# run する前にグラフ内の変数全てを初期化する
sess.run(tf.initialize_all_variables())

result = sess.run( op_var )
print( result )
#表示結果
# 1

# スカラー 2 を代入
op_asn = tf.assign(op_var, 2 )

result = sess.run( op_asn )
print( result )
#表示結果
# 2

result = sess.run( op_var )
print( result )
#表示結果 : 2 に変わっている
# 2

# 再びグラフ内の変数全てを初期化する
sess.run(tf.initialize_all_variables())

result = sess.run( op_var )
print( result )
#表示結果 : 初期値 1 に戻る
# 1
</pre>

<br>
<p>
データフローグラフ
</p>

<img src="./img/page04-fig9.png" alt="">
</div>

<script>PreNext(4,5)</script>
</body>
</html>
